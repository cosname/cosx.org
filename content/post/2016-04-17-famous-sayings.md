---
title: COS每周精选：名家名言
date: '2016-04-17T21:03:44+00:00'
author: COS编辑部
categories:
  - 每周精选
  - 统计之都
tags:
  - Feather包
  - 每周精选
slug: famous-sayings
forum_id: 419125
---

本期投稿：朱雪宁、[王威廉 ](http://weibo.com/u/1657470871?from=feed&loc=avatar)、王小宁；编辑：王小宁。

# 名家名言

王汉生：[传统制造业才是大数据的金矿](http://mp.weixin.qq.com/s?__biz=MzI4NzE4NzAxMg==&mid=2650285035&idx=1&sn=8da6ead967cdbd05ba7a83fb3376e504&3rd=MzA3MDU4NTYzMw==&scene=6#rd)

# R 包

突破数据框读写瓶颈，又一个造轮子的工作，[ Feather包](https://blog.rstudio.org/2016/03/29/feather/)值得一试。

# 行业应用

Airbnb使用[R做数据分析](https://medium.com/airbnb-engineering/using-r-packages-and-education-to-scale-data-science-at-airbnb-906faa58e12d#.k9o4q7q98)。<!--more-->

# 学习材料

剑桥大学信息论大神David MacKay在网上公开了他所讲授的16课时的《信息论、模式识别与神经网络》入门课程。看了一下，个人感觉David的入门课讲得算是出神入化，有很多很形象的例子，没有满屏幕的数学公式，可以让没有任何机器学习和信息论背景的人都能看懂。[视频链接](http://videolectures.net/course_information_theory_pattern_recognition/)。

特征学习和深度学习热门会议( International Conference on Learning Representations (ICLR2016) 的两篇最佳论文。[Neural Programmer-Interpreters](http://arxiv.org/abs/1511.06279)  和 [Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding](http://arxiv.org/abs/1510.00149)。
