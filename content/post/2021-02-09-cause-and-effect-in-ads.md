---
title: '广告届的因果推断挑战'
author: '陈丽云'
meta_extra: '审稿：丁鹏；编辑：向悦、黄湘云'
date: '2021-02-09'
slug: cause-and-effect-in-ads
categories:
- 统计应用
tags:
- 在线广告
- 因果推断
- 随机对照试验
forum_id: 422063
---

> 声明：本文引用的所有信息均为公开信息，仅代表作者本人观点，与就职单位无关。


广告界有一句经久流传的话：“我知道我的广告费有一半浪费了，但遗憾的是，我不知道是哪一半被浪费了“。人们对这句话有着不同的解读，其中之一就是广告效果衡量的不足。正因为无法很精确地衡量广告的效果，所以没办法进行进一步的投放优化，只能白白浪费。


毫无疑问，每个广告主都想知道自己投出去的钱带来了多大收益。换言之，这个问题其实就是广告投放的因果效应。这里的“因果”限定为统计意义上的因果效应——如果我们把投放广告看作一种“处理 (treatment)”，那么结果会有什么变化？在这个层面上，广告界对应的统计学问题“因果效应”和其他领域并无二致。本文就沿用统计学因果推断的语言，来分享一下广告界的因果推断面临的困难和挑战。本文着重描述问题本身，对于解决方案仅作开放性的泛泛讨论，留给读者日后思考。


## 序言：没数据？


广告效果衡量之所以难，正是因为“没数据”，即搜集数据的困难性。传统媒体广告，比如经常让人们津津乐道的在纽约时代广场投放的户外广告，其实是很难量化的。广告投放本身的花费是已知的，但其带来的曝光很难计算。比如，除了时代广场的人流量本身，还可能有媒体转载从而引发“话题”。就算曝光可以被追踪到，消费者行为的变化则是更加难以追踪。而我们的终极问题，“到底有多少新增的产品销量是跟某一则广告的投放相关”，就变成了近似玄学。


好在随着这些年互联网的普及，从互联网上搜集数据变得格外容易（比如“追踪像素”等实现了[跨站追踪](https://support.google.com/google-ads/answer/7521212?hl=zh-Hans)），由此互联网广告的效果衡量便乘风而进。各大互联网公司其实多多少少都是广告公司。美国市场上，谷歌(Google) 80%以上的收入来源于广告，脸书(Facebook) 更是占到98%以上，连传统的电子商务公司亚马逊(Amazon) 也开始受益于广告收入的快速增长。中国市场上，阿里巴巴40%多的营收来源于广告，腾讯有接近20%，百度超过70%，而新兴势力如拼多多、今日头条等等也很大程度上受益于广告收入。庞大的广告收入背后对应的是人力资源。互联网企业中很多人力资源其实是投放在广告方面的，其中就包括很多专门从事广告效果分析的团队。那么在在线广告这个环境中，人们遇到了哪些挑战呢？

### 1. 随机对照实验的困难

在现实世界中，一个结果的产生往往会受到多重因素的影响。因此，对于单一因素效果衡量的本质就是要排除其他因素的影响，从而得到该因素本身的影响。统计学上因果推断的框架有不少，其中最直接的就是基于随机对照实验，因为在随机分配实验组和对照组的时候，“其他因素”就被均匀分配了，唯一的区别就是处理本身，从而直接满足了统计学上所要求的“外生性”，故而也被很多人认为是因果推断的黄金准则。直觉上可以理解为，假如我有一对一模一样的双胞胎，其中一个看到广告另一个没看到，我就可以得出广告投放的效果了。虽然现实中没有双胞胎，但我的实验对象足够多，且我其实只关心总体的效果，那么我便可以把他们一分为二从而大致相当。

随机对照实验作为一个因果推断的框架，本身也是有很多一般性的挑战的。我们暂且不论哪些统计学上的挑战，单单在在线广告投放这个领域，随机对照实验的实施便没有人们想象的那么简单。医学上的随机对照实验可以使用“安慰剂”，而在线广告领域并没有那么显然的安慰剂，因为简单的“安慰剂广告”在经过广告投放算法优化之后，往往会带来实验组和对照组不可比的问题。我在2017年的时候曾经简单翻译过[谷歌的“幽灵广告”](https://cosx.org/2017/04/google-ghost-ads/)一文，其中对此有比较详细的解释。脸书等公司也有类似的实验工具，来帮助实现随机对照实验。当然，广告界的随机对照实验也无法避免随机对照实验一般性的问题。我曾经在其他文章里面介绍过随机对照实验的若干问题，这里就不再重复了。


这些在线实验工具适用的情况其实很有限，其中一个前提就是对于单一个体的广告投放是可以被控制的。这里其实依赖两个假设。其一，广告投放平台知道谁是谁。这个问题其实并不显然，因为用户往往有多个设备，他们并不一定会登录同一个账号，而本地缓存的用户登录信息（即cookie文件）本身也有有效期和适用范围的问题。其二，就算平台可以准确识别同一用户的不同身份，他们能不能控制针对这个用户的投放也不一定。很多时候，广告的买断是按时段和区域性，比如一群人一起在看重大体育赛事直播，从而他们看到的广告也是一样的。广告平台其实只能有效地控制一部分广告对于个体的投放，而不是全部。这一点虽然在线广告会比传统广告有着一些优势，但并不完美。


对于第一个问题，广告平台们往往采取统计预测模型来猜测用户身份，从而保证同一用户在不同设备上均可被识别。对于第二个问题，随机分配的时候可能就没法在用户这个层面上进行了，而更可能是采取区域或者时段的随机，但这又会带来新的问题，比如如何划分区域才是干净的同时保证区域之间的可比性，用户的记忆效应如何去控制，不同用户之间的相互影响如何衡量，等等。总之，虽然不完美，但是在随机对照实验可以被实施的时候，这依旧是好的办法。

### 2. 基于规则的归因（Attribution）

随机对照实验有种种的难处，那么大家就束手无策了吗？传统的因果推断教科书可能会开始介绍拟实验（Quasi-experimental）、各种模拟对照组的模型、工具变量，等等。其实换个思路，我们还可以利用更丰富的中间过程信息，找一个近似解，这就是广告归因模型（Attribution）。

严格地说，广告归因（Attribution）其实并不是一个数学模型，而是一系列基于假设的计算。比如，在用户的各种点击行为已知的情况下，我们可以设定一条规则：如果一个用户点击了广告，并且在1天之内完成了购买，那么这个购买就会被归因于点击的广告。这听起来很符合直觉啊，我看到广告有兴趣，然后点进去了，然后发现了我想买的东西，然后就买了，那最后的购买自然应该归功于我看到的那个广告。这种简单的情况可能符合某些购物的转化路径，但实际上人们的行为远远要比这个复杂。

- 反例1：一个用户可能连续点了多个广告才最终实现了购买，那么显然把所有的功劳都归于最后一个点击的广告好像并不公平。

- 反例2：另外一个用户点了广告看到了商品，然后当时没想买。结果过了几天，觉得还是想要，就回头去买了。这个时候已经过了1天的时限，所以购买并不会被归因于当时点击的广告。

- 反例3：还有的用户在看直播的时候看到的广告，但是当时并不会点击，因为还想看直播。可能看完直播，用户回味起来有个广告里的商品很有意思，然后又去买了。这种情况下，点击也不能完全捕捉到最终的购买。

理论上，如果我们可以穷尽所有用户实现转化的路径，是不是就能得到一个完美的归因模型了呢？可现实的情况是，用户的行为五花八门， 而且他们自己可能都说不清楚哪些广告是真正有影响的，这使得基于因果链的推理变得格外困难，只能得到一个近似的效果。当我们的假设贴近用户实际的行为的时候，这个近似可能不算差。但是当真实的用户行为与我们假设的归因规则相去甚远的时候，归因模型给出的结果就变得没那么可信了。当然，归因模型也可以用在随机对照实验的实验组上，然后就可以拿归因模型跟随机对照实验的结果去对比，比如利用 [Facebook 数据的这篇论文](https://www.kellogg.northwestern.edu/faculty/gordon_b/files/fb_comparison.pdf)。

当然，因为归因模型用到了额外的数据（点击、浏览、时间点等），所以它其实承载了比简单的随机对照实验更丰富的信息。这些信息除了简单地用于基于规则的归因之外，亦可以用于更丰富的模型设定。在下一节，我们会探讨在多个广告媒介之间的效果衡量，归因模型也会因此得到拓展。

### 3. 多个广告媒介平台

对于广告主来说，投放广告的媒体会有很多，所以基本上不可能只在一家投放。如果一个广告主同时在谷歌搜索和脸书展现广告，那么他们关心的问题就不仅仅是总共的效果了， 而是更想知道每一个广告媒介的效果，从而知道如何调整每个渠道的广告预算。这个时候，因果推断问题就变得更有趣了，因为多个广告媒介之间很可能会有交互效应。

第一种情况是，这些广告平台都支持某种形式的随机对照实验，这样问题就转化为一个全因子实验设计（factorial design）的问题。最理想的情况自然是在每个平台上随机分配的对象是一致的，同时还可以把同一用户在不同平台上的身份联系起来，这样其实只需要进行方差分析就可以了。现实的情况是，就算不同的平台都支持随机对照实验，他们允许随机分配的对象可能是不同的，而且几乎不可能是完美的匹配同一用户在不同平台上的身份。因此，虽然每个平台上的实验依旧是有效的，把多个平台的数据放在一起分析就没有那么简单了。数据可能需要进行不同层面的加总，然后才可以在平台之间有可比性（比如把属于同一个地区的用户都加总起来）。

更常见的情况是，随机对照实验变得几乎不实施。这种时候，归因模型因为其实施的便利性，得到了极大的拓展。常见的有多触点归因模型(Multi-Touch Attribution，缩写MTA)，其思想是考虑到用户在多个平台上的各种点击及浏览行为，然后把最终的用户转化分解开来，赋予每一个点击不同的权重百分比，然后加总计算每个平台的贡献。从这个思路来看，多触点归因模型依旧需要解决用户身份识别的问题，然后还需要把微观层面的所有行为数据汇总到一起，然后再假设或者基于经验赋予不同行为不同的权重，最终达成对于不同平台的归因。实践中，这显然不是一件容易的事情。

如果我们退而求其次，不要求保留用户的所有的行为数据，而直接利用汇总过的每个平台的归因数据，那么又会有什么样的思路呢？这时候就可以借鉴以前传统广告行业常用的市场组合模型(Marketing Mix Model，缩写MMM)，即利用回归模型来分配不同广告渠道的贡献。MMM虽然本身是一个简单的相关性分析(correlation analysis)，但是也可以引入随机对照实验的数据来进行改善。和简单的随机对照实验不同的是，MMM加入了广告主企业本身的数据，比如企业销售渠道、产品特性、成本等等，可以更直接地对整体的企业利润进行分解而不仅仅是用户转化。

到这里，其实已经对因果推断做出了越来越多的妥协。有些妥协是受限于数据本身，所以引入模型和更多的假设来进行修正，带着对于离真相更进一步的美好期盼。有些妥协是对于因果推断严格性的需求降低，比如决策本身并不需要单一地依赖因果推断的结果，关联分析也可以给出一些有用的信息，加之其他方面的信息，亦可以指导下一步的决策。


### 4. 用户转化数据的不可追踪性

前面三节讨论的情况有一个不太明显但很必要的假设：用户的转化数据是可以跟踪的，比如通过序言一节中提到的追踪像素之类。然而这其实也是一个很强的假设。在现实生活中，我们很可能没法对用户转化数据实现完美的追踪。比如，用户很可能去家旁边的超市买洗发水而不是跑到广告主的线上网站上去购买。虽然有一些机制，例如会员卡、鼓励用户扫描购物小票等等，可以帮助部分商家打通线上线下的数据关联问题，但这些解决方案的适用范围往往颇为有限，亦有时效性的问题。此时，一种思路是类似前面的，把区域内的数据加总起来，比如厂商往往是知道自己在每个零售点的销售额的，然后在区域的层面进行对比。另一种思路则是，既然追踪不到用户最终的转化数据，那有没有办法间接的衡量转化呢？

这个时候，我们不得不对于严格的因果推断做进一步的妥协。虽然不能直接追踪到用户的最终转化，但有没有其他指标可以近似地反映用户的转化呢？这时候，一切可能被搜集到的数据就被动员了起来。比如用户的注意力数据（停留时长、心跳、眼球注视范围等生理指标），用户对于问卷调查的反馈，等等。当然，这些数据的获取也不是那么容易，比如生理数据需要用户安装相应的追踪设备，所以一般来说都是基于特定用户或者在实验室中进行的。问卷调查需要用户愿意回答才行，而且可能发放调查的成本。总之，人们发明了各种基于想象力的办法，来搜集一些直觉上可能相关的代理变量(proxy variable)，从而给出一个近似解。至于这个近似有多么近似，可能很大程度上就是基于大家的经验和信念了。

在这种只有代理变量的情况下，用户转化就变成了一个隐变量(latent variable)或者部分观测变量(partially observed variable)的问题。取决于有什么样的代理变量，和转化数据是不是可以在特定情况下被观测到，我们可以引入不同的统计模型来充分挖掘数据的价值。当然这些方法可以和随机对照实验或者归因模型进行结合，从而得到因果效应的近似解。

### 5. 优化--如何实现广告投放效果的最大化

前面所说的基本都是一个“衡量”问题，即给定一个处理，如何衡量它带来的效果。衡量的结果显然可以用来指导广告预算投放的优化，但是对于广告平台来说，最重要的是提高广告投放的效率，尤其是不单单通过宏观层面调整预算分配的手段。理想的情况下，如果我们知道一个用户需要看10则广告才会转化，而另一个用户只需要看1则广告就会转化了，那么在预算有限的情况下，我们肯定希望找到那些更容易转化的用户。如果我们知道每个人对于每个广告的个体处理效应（individual treatment effect），那么这个问题不就迎刃而解了吗？

个体处理效应或许是因果推断中更近乎玄学的一个概念。某种意义上，统计学之所以带有统计两个字，本身是一个群体的概念，而从群体推论到个体并不那么直接。Rubin提出的潜在结果框架（potential outcome framework），某种意义上事先回答了一个哲学问题——当个体效应不可观测的时候，能不能观测到群体的平均效应呢？这里的“能”或者“不能”不是说计算的可行性，而是说这样做在哲学层面是不是有意义。随机对照实验显然是无法给出个体处理效应的结果的，那么匹配（matching）之类的方法会可行吗？通过时间序列或者其他模型来预测每个个体的潜在结果会可行吗？或者，我们用归因模型的近似解，是不是就可以绕过对于个体处理效应的依赖，直接去解决我们关心的广告投放的优化问题呢？

到这里，已经不单单是一个因果推断的问题了，而隐含了一场工程实现与哲学思考的较量。我有幸作为从业者，和我的小伙伴们在过去的十几年一路观察着业界和学界这些年不同的进展，细细品来其实颇为有趣。当然，还有一些其他的挑战，行业本身变化也很快，无法逐一叙述。这篇文章写下来，主要是想跟大家分享我的一些观察、思考和与朋友们的探讨。若是能引出更好的问题，也算是抛砖引玉了。

