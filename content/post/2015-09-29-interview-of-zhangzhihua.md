---
title: COS访谈第十九期：张志华教授
date: '2015-09-29T15:12:47+00:00'
author: COS编辑部
categories:
  - cos访谈
  - 推荐文章
  - 统计之都
tags:
  - COS访谈
  - ESL
  - Mike Jordan
  - MLAPP
  - PRML
  - 大数据
  - 张志华
  - 机器学习
  - 统计学习
  - 郁彬
slug: interview-of-zhangzhihua
---

<span style="color: #6c6c6c;">【COS编辑部按】 受访者：[张志华](http://bcmi.sjtu.edu.cn/~zhzhang/)   采访者：常象宇   文字整理：王莉晶 朱雪宁</span>

<span style="color: #6c6c6c;"><span style="color: #00006c;">[张志华](http://bcmi.sjtu.edu.cn/~zhzhang/)</span>，博士，上海交通大学计算机科学与工程系教授，上海交通大学数据科学研究中心兼职教授，计算机科学与技术和统计学双学科的博士生指导导师。在加入上海交通大学之前，是浙江大学计算机学院教授和浙江大学统计科学中心兼职教授。主要从事人工智能、机器学习与应用统计学领域的教学与研究。迄今在国际重要学术期刊和重要的计算机学科会议上发表70余篇论文。是美国“数学评论”的特邀评论员，国际机器学习旗舰刊物Journal of Machine Learning Research 的执行编委。其公开课《机器学习导论》和《统计机器学习》受到广泛关注。</span>

![张志华教授和他的学生们](https://cos.name/wp-content/uploads/2015/09/张志华.jpg)

<p style="text-align: center;">
  <span style="color: #6c6c6c;">张志华教授和他的学生们</span>
</p>

<span style="color: #6c6c6c;">2015年9月19日晚，在美丽的古都西安，张志华接受了常象宇博士(西安交通大学管理学院助理教授)的采访，王莉晶、朱雪宁对采访稿进行了一些文字上的整理和修改，全文最终由采访人常象宇和被采访人张志华审核定稿。</span>

<span style="color: #6c6c6c;">下面是访谈的全部内容。</span>

<span style="color: #000080;">常象宇：请您简单介绍一下您博士期间的研究和促使您出国求学的原因。</span>

张志华：当时在国内读博士的时候，我的研究主要是集中在利用模糊数学，神经网络与遗传算法、并利用它们解决图像处理、计算机视觉等中的问题。当时做这些方法还是发表一些论文，毕业条件也很容易达到的，但是自己隐隐约约总觉得这个领域不太对自己胃口。而且博士读了4年，之前博士论文基本完成。最后一年的空档期，我读到了Biometrika和JRSSB上面Peter Green和S. Richardson的关于RJMCMC(Reversible Jump Markov Chain Monte Carlo)的文章。RJMCMC的思想是把参数估计和模型选择放在一个统一的框架下进行。特别是，他们在JRSSB上的文章给出了求解单变量高斯混合模型的RJMCMC方法。当时用高斯混合模型去做图像分割是比较重要的方法，但通常是用BIC等准则进行模型选择，参数估计和模型选择是两个分离的过程。所以当时计算机视觉界关注到RJMCMC。但是我们遇到的问题不是单变量问题，而是高维问题。Green他们文章特别提到，他们方法推广到高维是Open Problem，并说这是个比较难的问题。当时我的第一感觉，我可以解决这个问题。我们利用SVD分解设计了相应的算法，效果也不错。但是里面的证明我还是没法解决，主要是缺少统计背景。但发现这些东西，我突然觉得特别喜欢，所以当时就决定改行。而在国内无法学到这些东西，也找不到相关书籍，当时上国际网是要付费的，不像现在获取资料如此方便。那段时间，在Mike Jordan教授个人主页上发现了他的统计学习的讲义“概率图模型导论”。那个时候下载1M需要大约5元钱。所以颇花了一番周折才弄到Mike 的讲义。读完之后收益非常大, 也喜欢上了统计学习这个方向。意识到相关背景自己缺得太多，而国内很难找到相关书籍啊。

<span style="color: #000080;">常象宇：您后来又是如何师从了国际著名的统计机器学习专家Michael Jordan教授的呢？</span><!--more-->

张志华：刚才谈到在读博士期间, 在Mike Jordan教授个人主页上发现了他的统计学习的讲义“概率图模型导论”。读之后收益非常大, 觉得做统计学习比较有兴趣。自然希望能有机会师从Mike. 2005年, 我在加州大学圣巴巴拉分校做博士后研究。我联系了Mike Jordan教授希望去他实验室做一段时间。当时正好在UCLA的应用数学中心有个暑期学校，Mike要去讲课，他强烈推荐我参加这个暑期学校。在UCLA的暑期学校上，见到了Mike和他聊的比较愉快。但他要求我去Berkeley他实验室去进一步面试。

我记得在Berkeley的面试是从早晨8点开始，好像是4位Mike学生1人和我谈1小时，中午12点左右我做一个报告，大家边吃边听我报告，当时我在读随机微分方程的书，想用它做一点非参数机器学习的东西，于是报告就讲这方面自己的一些看法。报告之后，接着和他另外3位学生1人谈1小时，到了下午4点左右，最后和Mike单独谈。他的学生和我谈的主要是他们研究中遇到一些问题，看我是否有解决办法。我对他们做的东西都还比较了解，数学方面知识面还算比较广，所以自己觉得和他们谈得还行。但是英文不好，中午报告有2个问题就没听明白其中的意思。和Mike谈时候，他对我专业素养还比较认可，就说我英文太差，将来在美国找工作会很难，问我是否愿意去香港或新加坡找工作。我告诉他，香港和新加坡的官方语言是英语，学校是用英语教学。他对我以后的工作问题有点犯难，我告诉他，其实我是可以回中国大陆工作的，他有点吃惊，“你真的愿意回中国？”我说，是啊，回中国没有什么问题的。他笑了起来，“那的确不存在语言的问题。”于是他告诉我他会尽快答复我他的决定。我起身告辞。回到酒店，才感觉到非常累。大约一周左右时间，我收到Mike同意接受我的邮件。

<span style="color: #000080;">常象宇：在Michael Jordan教授那里学习的最大收获是什么呢？</span>

张志华：在Mike那里学习收获当然巨大，学识、眼界和自信心都有了质提高。但最让我感动的是Mike的人格魅力。刚才你也听到了，他在面试我的时候，首先考虑到不是我去他那里能帮他做出什么，而是我将来的工作出路。另外，他对学生特性很了解，能“因材施教”。郁彬老师戏称Mike 会看相。我起先被安排在计算机系Soda Hall, 但一年之后，Mike 认为我长于分析，弱于计算，统计可能更适合我。于是我后来被安排统计系Evans Hall。Mike作为老师真是非常伟大，他当时和我说的是：你在伯克利机会难得，不如好好修些课，先不用过急做研究。之后我大量的时间都是在统计系学习高等概率，高等数理统计及统计机器学习等课程。有时候想想，一方面你和他没有“一日为师，终生为父”的负担，另一方面他对你的职业的发展又是考虑那么周到。其实他学生离开他实验室，去别大学任教和他就变成了竞争关系。

<span style="color: #000080;">常象宇：又是什么事情促使您回国发展的呢？</span>

张志华：一是2007年至2008年期间，机器学习正处于低期，国外教职不好找。当时和华尔街一个公司谈过，他们希望去做一些拍价竞标的东西。但是总觉在学术界这么长时间，有点不甘心。二是在统计系时和郁彬老师办公室离的比较近，她鼓励我回国，说是国内统计机器学习领域空白，而且她还和Mike谈了，郁老师对国内统计学和机器学习的发展是有使命感的，你是她的学生，你应该感觉到的。前面我也提到之前和Mike有承诺愿意回国的。由于我在伯克利的统计系学习了大量的统计知识，自己也深深喜欢上了这个学科，所以当时回国是想去国内高校的统计系任教。但机器学习当时在国内统计界的确是空白，还没被认同。比如，机器学习比较认同一些顶级会议比如NIPS，ICML的文章，当时根本得不到国内数学届和统计界的认可。所以后来还是去了计算机界任教。

<span style="color: #000080;">常象宇：您在香港，美国等地做研究多年，又曾经在Google，微软等公司的研究院访问过，最后又在国内的高校任教。您能通过亲身的经历，谈谈这三个地方工作与研究的异同嘛？您更喜欢在哪个地方？</span>

张志华：2012年，Google有一个全球Faculty的计划。我申请后通过了。该计划会资助某个学者在Google访问一年。微软亚洲研究院都是短期访问的，一般不超过三个月。在Google，我主要参与了两个项目：第一是大规模LDA方法的分布式或者在线算法的实现。第二是室内定位相关技术。同时我的任务还包括了每个星期负责给工程师讲授统计与机器学习方面的相关课程。这些大公司除了赚钱，它们对这个世界文化、价值还是有某种使命感的。相比于国内高校，我还是觉得美国的高校氛围更纯粹，老师职责也更单纯一些。

<span style="color: #000080;">常象宇： 我们知道您关于机器学习的网络公开课非常受欢迎，您也刚才提到您对于教学有浓厚的兴趣，能说说其中的原因吗？</span>

张志华：我的想法是，教学对于自己的业务提高是很好的，教学相长。我经常给学生说，我从来不上无谓的课。我不会因为为了完成工作量而去上没有必要的课。我的教学的特点是一定坚持写黑板。我和学生说，到了我这个年龄，专注度，体力，精力等都是在下滑的。坚持写黑板是对于自己的一种磨练。其实另一方面是我受到Mike的影响。Mike的统计功底是教学教出来的。

我曾经反思过，一年到头总在忙：在忙各种论文，在忙项目申请，但是每年收获最大的就是上课的那几个月。当然，年轻的老师上课太多也不是太好。但是如果能够按照自己的思路设计每年讲授一两门自己想教的课程，那么对于年轻人是有极大帮助的。但是国内的体制一般也是不容易达到，作为教授还稍微有一些自由选择的权力。我最近写了个“教学感悟”。你有空可以读读，提提意见。

我那个公开课能够放在网上，并且还比较热门纯属意外中的意外。当时我刚到上海交大任教，招了第一批学生。刚好系里希望我为ACM班、IEEE班两个大三班级讲机器学习，而且因为他们是试点班，不能合班上。ACM班是俞勇老师负责，他特别要求我要讲机器学习中的统计原理。所以我就想利用这个机会，系统地从统计和优化两个不同角度分别讲机器学习。让我自己学生全程旁听，负责记录、整理教学笔记，同时请教务处帮找公司录下讲课过程，以便以后的学生可以自己来看。但是录制费用需要5万元左右。说来惭愧，我没有经费能够支持该费用。学校教务处出了这笔费用，于是他们制作成网上公开课。但是应该说比较粗糙，目录还有些错别字，当然我的板书也比较乱。以后如果可能机会再录，一定要弄得更精细一些。目前，外校一些同事反映视频有点卡，我和教务处商量一下，看能否允许直接放到某个公开网站上。

<span style="color: #808080;">编者注，公开课地址：</span>

<span style="color: #808080;">机器学习导论：[http://ocw.sjtu.edu.cn/G2S/OCW/cn/CourseDetails.htm?Id=397](http://ocw.sjtu.edu.cn/G2S/OCW/cn/CourseDetails.htm?Id=397)</span>

<span style="color: #808080;">统计机器学习：[http://ocw.sjtu.edu.cn/G2S/OCW/cn/CourseDetails.htm?Id=398](http://ocw.sjtu.edu.cn/G2S/OCW/cn/CourseDetails.htm?Id=398)</span>

<span style="color: #000080;">常象宇： 回到国内之后，您培养出了很多优秀的年轻人。例如：获得百度奖学金的[王树森](https://sites.google.com/site/zjuwss/)和[张雨辰](http://www.cs.berkeley.edu/~yuczhang/)，微软学者王树森、石建萍，谷歌奖学金的王乃岩，他们直接或者间接都是您的学生。您在平时是怎么教导您的学生的呢？我想很多想和您一起做研究的学生都很有兴趣知道。</span>

张志华：[树森](https://sites.google.com/site/zjuwss/)、[建萍](http://shijianping.me/)和[乃岩](http://winsty.net/)是我在浙大工作时带的第一批本科生，他们是竺可桢学院，学校对他们有进入实验室的培养机制。树森后来选择继续跟我读博士，建萍和乃岩则去香港读博士。现阶段他们的确在中国博士生里是比较优秀的。[雨辰](http://www.cs.berkeley.edu/~yuczhang/)是我在MSRA访问时认识的，当时他的两位mentors陈伟柱和王刚是我的host, 他们对雨辰赞不绝口。雨辰的确非常优秀，他的数学直觉非常好，我就跟我两位朋友说:“你们就把他当你学生，不要让他做公司项目。”他后来拿到很多美国一流学校的offer, 选择有点纠结，征询我的意见。我强烈建议他去Berkeley, 去跟Mike Jordan。 我在Google访问期间，也带过几位姚班学生做实习生。其中1位后来来交大我这里继续呆了半年。目前我在上海交大实验室有6位ACM班本科生，在浙大时曾经就有1位ACM班来学习半年。能有机会和国内计算机最优秀这批学生结缘是我人生最得意的一件事情。

我的原则就是“就把他们当学生！！！”。即使在谷歌，我也不让这帮学生做具体项目。我主要根据他们兴趣，推荐一些数学书给他们，再找点合适文章让他们读。他们做出了很多优秀的工作，你说我能有多大的贡献，最后都是他们自己做出来的。

我对我的研究生也基本遵循这个原则，把他们当学生，而我就是“老师”。现在当“老师”难是因为你要让学生做“项目”，这样产生了利益关系，那么就变成了“老板”。而如果在国内所有的学生都真的当“学生”，有时候我们当“老师”也很难，因为我们必须做项目。到现在为止，我一直坚持不接横向项目，但是坦率地说，我应该坚持不下去的。

<span style="color: #000080;">常象宇：John Wiley出版社向您约稿了一本机器学习的书籍，您能讲讲这个事情吗？</span>

张志华：John Wiley公司联系我是2014年初，当时他们统计部Debbie Jupe女士问我是否参加AI&STAT，她想和我谈谈，写一本统计机器学习书的可能性。但是不巧的是我没有计划参会。后来Jupe女士给我寄了一份他们的打算和目的，并且告诉我John Wiley 的统计书籍是业界翘楚，能在此出版一本书是很值得期待的，建议我认真考虑。我统计学的启蒙教材就是John Wiley出版的“An Introduction to Multivariate Statistical Analysis”(T. W. Anderson) 和“Aspects of Multivariate Statistical Theory”(R. J. Muirhead), 这两本书我一直带在身边。因此知道这个出版社在统计界的地位，所以觉得如果自己能够在上面出版一本书，那是相当有成就感的一件事。

另外，Springer已经出版了ESL(The Elements of Statistical Learning)与PRML(Pattern Recognition And Machine Learning)，MIT出版社出版了MLAPP(Machine Learning: A Probabilistic Perspective)和Foundations of Machine Learning。但是目前John Wiley 还没有类似的统计机器学习的书籍，应该是一个机遇。但是当然这也是大风险的，因为有这么多经典，如果没有任何超越，那就是科研自杀。之前，偶然也想过写一本书，但是规划是等50岁以后，觉得自己目前还在研究高峰期，还想在一线继续做几年。但是连续几年经费申请诸多不顺，一无所获。难以维持实验室的支出。有点心灰意冷。最后我决定接受他们的邀请，写这本书，也算是对自己的一个总结吧。于是我给出版社写了一个目录和proposal. 出版社拿出去审了一个多月。一个多月之后，收到了出版社的回复，其中有统计专业的教授评审意见说这个人没有统计的背景，但是他又发表过一些统计的论文，所以对这个书籍能不能写出统计的味道还是有些顾虑。但是出版公司主编还是最终决定了出版计划，给我发来合同。我记得清楚，我是去年教师节那天签了合同，寄给他们的。

<span style="color: #000080;">常象宇：和ESL，PRML，MLAPP相比您的书是一个什么样的定位呢？</span>

张志华：你提得很好，包括“All of Statistics”，以及Mike至今没有出版的“Introduction to Probabilistic Models”这些经典。 这也是我刚才提到的顾虑。 ESL和其他两本书是完全不同的，完全是频率学派撰写的。其中加入了很多优化的思想。另外两本书还是比较相似的。他们的三本书其实相对于计算机背景的人还是太简洁了，里面充斥了大量的统计思想，计算机背景的人想去理解还是有一定困难的。我这本书的立足点就是给这些书籍写个前传。就像“射雕英雄传”，我写个“射雕英雄前传”。就把前面的东西交代的更清楚一些。不是突然跳出一个“洪七公”，而是要把“洪七公”的背景给你交代的更清楚，后面的东西可以写的简略点。以前的书籍更像突然杀出一个中神通、南帝、北丐、东邪、西毒，华山论剑，当然过瘾。我的书籍就是把他们“武功背景”的统计基础交代的更仔细些。这样大家知道背景了，想去练习“降龙十八掌”，或者看他们论剑，能看出一些门道，而不仅仅是热闹。这方面其实是计算机出身的人更需要的。

<span style="color: #000080;">常象宇：您能谈谈对于“大数据” 的认识吗？</span>

张志华：“大数据”的确是有这个问题，有这个现象。它目前还不是一个学科，不是一个概念。我想我们目的是希望从大数据中挖掘出一些有价值的信息，因此，核心应是大数据的处理和分析。我理解应对大数据有三个关键问题，数据建模、计算和实现平台。所以解决大数据问题，关键还是机器学习或者统计机器学习。建模方面，我觉得统计学家已经无论工具和理论都基本上为我们准备好，我们可能只需要根据问题组装成需要模型。理论上，我们知道统计学家总是要讨论模型的“相合性”(consistency)，即n(数据个数) 趋向于无穷时，模型的相合性。我理解n趋向于无穷，不就是意味大数据了吗？所以统计学家已经考虑大数据理论问题，至于大数据另一方面，p(数据维数) 也可以趋向无穷。最近10年稀疏学习理论关于这方面，也已经有许多成熟理论。因此，我觉得，模型及其理论统计学家基本为我们准备好了。剩下计算和实现平台，这方面工业界其实做得不错，比如Hadoop、MapReduce。国外学术界做得也很好，像Berkeley的Spark, CMU的GraphLab和Petuum等。反观我们国内学术界，宏观、哲学层面的讨论多，微观、实证性的东西做得好像少一些。
