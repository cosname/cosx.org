---
  title: "统计之都访谈第44期：life is an exploratation-exploitation tradeoff--雷理骅访谈"
date: "2022-08-09"
categories:
  - COS访谈
tags:
  - cos访谈
- 统计学
- 教育
- 发展
- 八卦
slug: interview-of-lihua-lei
meta_extra: "采访：蔡占锐；录音审校：朱书慧，闫涵超，梁杰昊，赵昊蛟，孔令仁"
forum_id: 423404
---
  
  2022年8月初，正是北美一年一届的 Joint Statistical Meetings。统计之都在会议间隔对雷理骅进行了采访。在本文发布之际，雷理骅正迎来作为斯坦福大学商学院助理教授的第一个学期。本文采访者是蔡占锐，是爱荷华州立大学助理教授。文中涉及到一些专业学术讨论，望诸位客官见谅。
  
  
  ## 1. 个人与过往经历
  
  **统计之都**：首先，能不能请你先讲讲个人经历呢，让我们的读者对你有个直观的认识，也不需要谦虚。

**雷理骅**：大家好，我是雷理骅。非常感谢统计之都的采访，也很高兴能跟大家分享我的经历。我现在是斯坦福大学统计学系的博士后研究员，导师是 Emmanuel Candès 教授[^1]。此前，我获得了北京大学数学与统计和经济学的学士学位，并在加州大学伯克利分校获得博士学位。

> 后文 Berkeley 即为加州大学伯克利分校（University of California, Berkeley）

[^1]: [Emmanuel Candès](https://profiles.stanford.edu/emmanuel-candes)


说到个人经历，我从小就比较喜欢数学。我在小学开始接触数学竞赛，到高中的时候进入了华师一附中的竞赛班，从高二开始全身心的投入准备竞赛。后来我获得了 CMO （中国数学奥林匹克）的金牌并被保送到了北大。

在保送结束到开始上大学之间, 大概空出了半年的时间，在这段时间里我进行了一些很有趣的探索，也第一次接触到（医学）统计。我的母亲在医院工作。她在临床很多年，发现很多卧床很久的老年病人会得一种病，叫做压疮，这种病会对老年人的生活质量产生很大影响。母亲阅读文献后发现，营养支持是避免产生压疮的一个很好的方法。她当时是医院的护士长，所以一开始亲自动手，收集到了多达300例非常高质量的病例数据。当时的我还不能理解这件事的意义，现在回头看，觉得这是非常了不起的事情。之后医院的其他同事也加入进来。在我高三的时候，数据量已经达到了1000例以上。自然而然的，母亲想对这批数据做一些统计分析。比如研究不同的指标对压疮的影响。那时的我还不太明白统计到底是什么。我在高三的数学选修课本里简单接触过一点统计知识，但大都是一些简单的结果，并不理解为什么会有那种形式（比如正态分布，列联表等）。但母亲觉得我是学数学的，对我来说统计应该也不难，于是她给了找我一本医学统计的教材。这本教材里有许多医学统计要用到的方法，比如卡方检验。我运用 SPSS 软件，跟着教材上一步一步的操作，最后生成了一个非常漂亮的报告。这对于当时还在高中的我还是很震撼的。当时突然一下，我觉得统计这个学科好像可以把我们学到的这些数学公式，变成一些在现实中非常有用的东西。于是，在还没有进大学的时候，我就基本决定未来是很想做统计的。

**统计之都**： 进入北大之后，肯定学习任务也是相对繁重的，你能讲讲整个本科阶段你自己的个人的时间分配，是如何学习的吗？

**雷理骅**：其实在前面两年半时间，我的时间安排总体来说是这样：首先一大部分时间是用来学习专业课，一方面是我觉得这些课程很有意思，另一方面也确实在北大数院还是有压力，所以说还是要好好搞。另外的一大部分时间，我在北大咨询学会做了一年半的咨询。这是由于一开始我没有打算出国，也没有打算做学术，而是非常想进入业界。在这过程中，我在一个公司实习做过期货交易，还做了小半年的市场营销设计问卷，试图帮一个公司推销一个产品等等。另外，由于对经济金融感兴趣，我还辅修了经济学双学位。但是在大三下的时候我突然意识到，其实这些跟商业、金融、经济这些工作可能跟我的性格不是那么的匹配，虽然我很喜欢，但我还会有些犹豫是否要把它们作为职业。与此同时，我在做这些事情的过程中接触到不同的统计，比如说在做期货交易的时候接触到时间序列，在做市场营销的时候要分析问卷数据。真正做数据分析的时候需要考虑的很周到，而当时我发现，以我在本科课本上学到那些东西是远远不够的。所以从那时候开始，我觉得我应该更深入的学习统计这个学科，去走到前沿去看看统计学术圈的人们 到底在学什么，然后我再决定是否要回到业界去使用这些统计知识。所以从那个时候开始，我才临时准备出国准备读博士，这大概其实是我的时间分配。

我觉得从某个角度来说，确实是走了弯路。但是回过头去看，我会觉得这段经历非常的宝贵。虽然我现在做的研究很理论，但很多研究的背景其实是源自于经济学。在那段时间里， 我选课加旁听，大概上了七，八门CCER（北大经济学双学位）的课。这个过程让我了解了很多经济学家去思考世界的方式。我们当时也跟MBA一起上过统计的课。他们对统计学在实际中的应用有很强的直觉。这个过程让我对统计的应用有了更深入的了解，也对之后选题做理论研究有很大帮助。

**统计之都**：最终为什么选择了统计的方向？选择了 Berkeley 并选择了 Peter [^2]作为导师？

[^2]: [Peter J. Bickel](https://bickel.stat.berkeley.edu/)

**雷理骅**：这也是一个很有趣的故事，在我大四上学期的时候，申请季结束之前，Peter 正好来北大和清华做了三天的讲座。那个时候我跟陈老师（陈松蹊老师）[^3]做的科研正好用到了 Peter 在六几年写的一篇文章。当时看到 Peter 要来就很高兴，想找他聊一聊，于是那几天我就一直在跟着他。Peter 人非常好，真的就是坐下来跟我、陈老师，还有涂云东老师[^4]，一起聊了差不多一个小时时间，他提供了很多非常好建议，我们非常感谢他。后来我就给 Peter 写邮件，说我很想申请Berkeley，是否可以？也把我跟吴岚老师[^5]一起做的科研的幻灯片发给了他。没想到他在 10 月份左右的时候回复我了，他说我还记得你问我的问题，然后我看了你 的幻灯片，觉得挺好的，欢迎申请 Berkeley。虽然我不在招生委员会，没有什么话语权，但如果你来的话一定要跟我说。所以这也是一种非常奇妙的缘分吧。

[^3]: [陈松蹊](https://www.math.pku.edu.cn/jsdw/js_20180628175159671361/c_20180628175159671361/118001.htm)

[^4]: [涂云东](https://www.gsm.pku.edu.cn/jsjjxq.jsp?urltype=tree.TreeTempUrl&wbtreeid=1141&user_id=yundong.tu)

[^5]: [吴岚](https://www.math.pku.edu.cn/jsdw/js_20180628175159671361/w_20180628175159671361/69977.htm)

**统计之都**： 能讲讲在北大，在 Berkeley，在 Stanford 时有意思的经历吗？

**雷理骅**：其实刚刚说的也一定程度上反映了有意思的事情。在北大期间，我觉得在科研上面比较有意思的事情是我和吴岚老师做的本科科研。最初做的是和金融数学有关的方向，想做实物期权的研究，就是用期权定价的方式对公司定价。其实这个想法很简单，就是选择卖掉公司获得收益还是继续经营公司来获得未来的现金流并折现到现在，所以这个就跟期权本身很像，一个是未来价格一个行权价格，但现在对公司定价来说这两个变量都变成了可能取决于其他很多因素的变量。最初我们会读一些咨询方面的内容，但后来我想能不能用一些统计方法，可不可以用中国 A 股市场的数据来估计一下这个模型，再看看能不能从中发现一些有趣的现象。于是我就想把它做成一个统计模型，其中一块和公司经营有关，另一块和当前市场有关，然后我的输出预测就相当于两个线性模型的最大值。这个方法和统计里的线性模型隔得不远，它们有本质差别，因为首先这个模型就是非凸的，在计算上就有困难，此外也难以推广结论。不过也就是基于这个契机我也去接触了improve process之类的东西，另外一方面我后来发现这个模型并不总是可识别的，两个线性组合之间有夹角的时候才能识别出来，这也让我意识到不是所有的模型写下来就可以估计。【英文需要精听】

在 Berkeley 的话我觉得和 Will Fithian [^6]的合作很有意思，我想我们之后聊到研究的时候会再聊到这段经历。

[^6]: [Will Fithian](https://www.stat.berkeley.edu/~wfithian/)

**统计之都**：除了学业外，生活也很重要，你的兴趣爱好是什么？

**雷理骅**：其实我是一个比较宅的人，不过在加州也不会太宅，因为加州有很多很有户外活动，比如说去徒步旅行或者去滑雪。再就是打桌游、看剧，因为加州中国留学生非常多，所以经常能叫到一大帮人开车去滑个雪，或者说夏天有一些活动，和大家一起去烧烤、打桌游，这些都非常常见。我本人并没有特别多的爱好，所以基本上就和大家一起热闹。到后来，尤其是疫情前，就主要靠看剧来消遣。

## 2. 研究

**统计之都**： 能仔细介绍下你主要研究的几个方向吗？

**雷理骅**：在读博士我的研究方向大概有三个。首先，最主要的研究方向是多重检验（multiple testing），关注的焦点在False Discover Rate control。第二个方向是因果推断（causal inference）。第三个方向是网络聚类（network clustering），我的研究焦点主要在谱聚类（spectral clustering）。在博士时候还有一个方向是优化。这个主要是跟 Michael Jordon[^7]一起做的。

在博士后期间，我开始进入到一个比较新的方向，叫conformal inference。这个目前可能还没有一个很好的翻译。这是个非常新的课题。在我进入到这个领域的时候，它还只能算一个研究课题，但现在过了三年以后，已经算是一个研究领域了。目前这个领域有非常多的人，大家非常有创造性的在思考conformal inference这个框架能用到什么问题上去。我从博士到博士后过程中，我也有幸认识到Guido W. Imbens[^8]，然后做了一些计量经济学的工作。

[^7]: [Michael I. Jordan](https://people.eecs.berkeley.edu/~jordan/)
[^8]: [Guido W. Imbens](https://www.gsb.stanford.edu/faculty-research/faculty/guido-w-imbens)

**统计之都**： 现在很多学生本科时就有所谓的“本研”，在你回头看来，你觉得重要吗？你是如何看待的？

**雷理骅**：我觉得非常重要。就我刚才说的几个例子，一个是跟吴岚老师的例子，他就让我意识到要怎么从一个实际的问题出发。本身这个问题它是一个很概率的问题。但是我逐渐地把它分类成一个统计的问题，这个统计问题就变成了一个新的问题，我就会去想怎么去估计？怎么去找一个好的算法，怎么去做实验模拟？怎么去推理性质？所有的这些过程就相当于让我独立地能从一个问题里面看到另外一个问题，然后把它转化成我自己的一个研究方向或者一个研究课题。

**统计之都**：相当于有一个完整的训练提升的过程。

**雷理骅**：对，这个过程我觉得非常重要，因为它能让你看到科研的每一步。当然作为本科生，我们可能每一步都做得不尽人意，但是对整个过程的全貌的理解，我觉得是非常重要的。像跟陈老师的科研让我理解到在应用中有多少tricky的问题，以及怎么跟不同领域的专家去沟通、去合作。这个过程也是我在本科科研的时候学到的。因为到后来发现，这些东西其实是很重要的。比如做一些理论的工作的时候，如果你继续用非常理论的方式去跟科学家沟通，就会发现他们没法理解你到底在说什么。因为你跟不同领域的科学家合作，是希望得到很有趣的问题，并实际解决一些问题，更希望能在这些不同的领域里面有一些实际的影响。但是如果沟通不力，合作起来会比较困难。

**统计之都**： 你在博士和博后阶段的工作有很多，你是如何寻找到这样有意思的题目的？解决这些问题你又遇到了哪些困难，或者说对你都很简单？例如与Will Fithian的合作 on FDR control （代表作?）是否和选择Candes做博后有关？与丁鹏 (causal inference)，Michael Jordan (optimization)的合作又是如何开始的呢？

**雷理骅**：统计一个特别好的地方在于，能研究的问题真的很多，相信大家应该都有这样的感觉。统计里面一个常见的说法是the statisticians can play in everyone's backyard or even frontyard。所以我们面临的问题很多，我们可以去做的问题也很多。我觉得很多时候其实是看机缘巧合。除了我开始跟Peter J. Bickel和Noureddine El Karoui做的 High Dimensional M Estimator，是我当时觉得这个很感兴趣，Peter鼓励我去做这个课题；博士期间基本上其他大部分课题都是我无意中找到的。但这个“无意”也不是说就真的无意。

注：https://arxiv.org/abs/1612.06358

**统计之都**：也是需要一些积累的。

**雷理骅**：对。其实我当时一个技巧就是我会去上大家的专题课程。我觉得这是我们接触新的科研领域的一个很好的方法，因为一个新的助理教授（AP）来到这个学校以后，他会想招学生，很多系里其实都会支持新来的助理教授开一个专题课程，讲自己的研究领域。有了这个机会以后，你就能很快的接触到一些最前沿的东西，因为一个新的AP来了，很有可能他做的东西，还没有构成一个领域，他们可能还在初期，但是因为他们做的很出色，所以说他们就被招进来了。在他们讲的过程中，其实这个专题课程更像是在跟学生在探讨，他们也在让自己的思维更加完善，通过交流的过程让自己有更完善的研究计划。在这个过程中能学到很多，比如说我最先接触到multiple testing，是因为上Will Fithian的这个专题课程，叫Selective Inference。其实一开始我对Selective Inference的理解非常狭隘，我一直以为Selective Inference就是说 Model Selection之后去做Inference。我也知道早期的一些工作需要用到很特殊的参数模型的性质，比如说我们做LASSO的 Selective Inference就需要假设Everything is Gaussian。但上了这个课以后才发现，首先Selective Inference是一个很大的领域，比如False Discovery Control就是属于Selective Inference。其次Post Selection Inference，包括Adaptive Data Analysis和Differential Privacy，其实也是隶属于Selective Inference。我在上课的过程中逐渐发现这是一个非常有趣的领域。当时Will Fithian讲这个课的时候也借用了一些Emmanuel在当时上的300C，那时候也差不多是Emmanuel刚刚进入到这个领域不久，他在Stanford开了一门课叫300C，讲很多family-wise error rate， false discovery rate control的东西。所以当时我有机会接触到了这样一些课题，当时我就觉得FDR是一个让我特别感兴趣的领域。于是我就利用到这个机会，在做最后Final Project的时候，我就花了很长的时间。当时我停掉我手里的研究。

**统计之都**：和Peter的研究？

**雷理骅**：对，或者说当时可能我停掉了其他一些我正在想的一些问题。当时那个阶段应该是第二年初期，那时候跟Peter也陷入到一些瓶颈，当时就想既然如此，我就好好的把时间花在Final Project上，我就想我能不能做一点东西。其实当时我就选了一个很小的切入点，当时我就读了Knockoff这篇paper。我就在想Knockoff当时是generate一个Copy of Knockoff，然后把Data转换成一个binary p-value。它的好处就是,如果说你是考虑一个线性模型，你需要N大于等于2P，aspect ratio的要求很低，但是它会让p-value的Resolution不是很高，就会导致一个问题，这个问题比较Tricky，但简单来说它会有个threshold phenomenon，就意味着如果你想把FDR control 在 0.1 这个level，你要么是Reject十个以上，要么Reject Nothing，但是实际情况下，很多时候我们大概Rejects五六个左右。那么这种情况下可能就没有办法给出一个很好的结果。所以那时候我就想做一个所谓的Multiple Knockoff，当然现在已经被人做出来了。当时我也做出来一些结果，但做出这个结果以后，我就给Will看，他觉得很有意思，于是我们从我做的结果那里，首先写了一篇文章。我们把Knockoff背后的一个叫selective six step filter推广了一下。就首先我和Will就先写了一篇ICML paper。我们就只是谈一下这样一个generalization，就是说我们不再用filter用在Knockoff上，我们就用在传统的p-value setting上，看我们能得到什么。很快我们做了这个项目以后，就意识到其实我们做的事情可以解决一个很重要的问题，叫data adaptive FDR control。这个motivation就在于，比如说在很多genetic data上，我们做multiple testing试图要control FDR，但是我们有很多side Information。这sign Information可能来自于别的实验，或者来自prior knowledge，我们怎么把这些prime knowledge纳入到我们FDR里面，使得它的power更高。我们在不断的聊天中，我记得那段时间跟Will Fithan可能是每周都聊一次，甚至聊两次，一聊可能就聊一个小时。在不断的这种iteration过程中，我原来当时Final Project里面一个想法，可以把它变成一个非常有力的工具。最后就我们写了adaptive这篇文章，想法非常简单，就是说我们有p-value。传统的方法就是直接用p-value做testing，但现在我们不是直接用p-value做testing，而是我们先隐掉一些Information。就是我们只给researcher看minimal p和1-p，以及其他所有的side Information。非常神奇的是，你只要用这些信息去估计任何的模型，哪怕这个模型是错的，是misspecified，最后在一些标准的假设上仍然可以保证FDR control，这就是我和Will写的那篇JRSSB[^8]。所以我后来一直在follow FDR上面的工作。我觉得非常有趣，因为当时它让我意识到，原来这么一个事后看起来非常简单的trick，它可以有效的把统计的testing和机器学习结合在一起，并且它的理论性质非常的强，就在于它所有的control都是finite sample，没有任何asymtotic，它允许模型是个任意的misspecification。但是如果你model是correctly specified，它会让你的power比较高。而这个工作本身其实也奠定了我后面所有工作的一个理念，就是无论是哪个方向，我都比较喜欢model free，distribution free，以及finite sample guarantee。我并不是觉得一定要有finite sample guarantee，而是觉得finite sample guarantee的这些方法，一般来说，有个特点，就是它一定会简单。因为说实话，很难想象一个非常复杂的方法，最后能给你发现finite sample guarantee，而且很多时候，背后的数学也会很简单。这个“简单”并不是在于它很容易想，它有时候可能很难想，但是数学证明都不会很复杂。
**雷理骅**：对，或者说当时可能我停掉了其他一些我正在想的一些问题。当时那个阶段应该是第二年初期，那时候跟Peter也陷入到一些瓶颈，当时就想既然如此，我就好好的把时间花在Final Project上，我就想我能不能做一点东西。其实当时我就选了一个很小的切入点，当时我就读了Knockoff这篇paper。我就在想Knockoff当时是generate一个Copy of Knockoff，然后把Data转换成一个binary p-value。它的好处就是,如果说你是考虑一个线性模型，你需要N大于等于2P，aspect ratio的要求很低，但是它会让p-value的Resolution不是很高，就会导致一个问题，这个问题比较Tricky，但简单来说它会有个threshold phenomenon，就意味着如果你想把FDR control 在 0.1 这个level，你要么是Reject十个以上，要么Reject Nothing，但是实际情况下，很多时候我们大概Rejects五六个左右。那么这种情况下可能就没有办法给出一个很好的结果。

> JRSSB: Journal of the Royal Statistical Society: Series B (Statistical Methodology)

[^8]: [AdaPT: an interactive procedure for multiple testing with side information](https://rss.onlinelibrary.wiley.com/doi/10.1111/rssb.12274)

**统计之都**：对。所以这个是不是和后来去 Emmanuel 那去做博士后有关系？

**雷理骅**：对，没错，其实关系非常的大，就在于我进入到这个领域以后，我就会去开这个领域的会。其中有一个会叫 WHOA-PSI ，这个会一直在 Saint Louis（圣路易斯）开。这个会开了很多年，但是现在很可惜，因为疫情停了，不过我们有一些延续，这个可以之后再说。

> WHOA-PSI: Workshop on Higher-Order Asymptotics and Post-Selection Inference

这个会，它聚集了很多做selective inference和high order inference的人，其实是两个community。Todd Kuffner从第一届开始就一直在组织，接下来的每一年他都在，至少是一个主要的组织者。这是2016年开始的。这个会对我其实帮助非常大。首先这个会是一个小规模的，相当于把这个领域里面所有人都请过来了，以及一些可能跟这个领域相关的人请过来了，所以在里面你可以直接见到所有这个领域里的人，大家做的课题也相对来说比较接近。在这个过程中，我也认识到了很多人，其中包括【人名】。我当时跟他做博士后，其实我一开始决定做博士后的时候，我觉得想跟谁，我觉得Emmanuel是我最想跟的人。当然，那时候我也不确定Emmanuel会不会带博士后，也不确定他会不会对我的研究感兴趣。但有幸的是因为Emmanuel也会去参加这个会，而在我会介绍adapt的工作，我也present过poster，后来我做了一下FDR的工作，这样Emmanuel也非常感兴趣。Emmanuel就对我们的工作评价很高，所以当时我在提出我想跟他做博士后的时候，他直接欣然的答应了。

**统计之都**：那么其他的一些工作，比如与Michael Jordan的优化领域的合作又是怎么开始的呢？

**雷理骅**：跟Michael Jordan的合作其实也是来自于一个巧合，一开始我在选了Peter作为主要的导师以后，一般来说，在Berkeley很流行的是再找一个co-adviser。一开始我还没有一个很明确的想法，但那时候我上了 Michael Jordan的Theoretical statistics。这门课是我们的核心课程。Michael讲得非常的好，在那个课最后期末我考得还比较好，所以Michael主动联系了我，问要不要聊一聊。后来我跟Michael聊了以后，他就邀请我去他的组会。然后我发现Michael的组会非常的有意思，它跟传统的组会不太一样的，就在于他有很多的学生。如果说大家都介绍自己的工作，会显得很杂乱无章。Michael选择一种非常不常见的方式。他会让大家一起来读书，而读的内容很有可能是组里没有任何人在研究的东西。比如说我第一个学期去的时候，他竟然在读Mostly Harmless Econometrics[^9]，是economics里面非常经典的教材，第二个学期就要读Bradley Efron的Large-Scale Inference[^10]，就是FDR。所以我说这是也有一些机缘巧合，我那时候感兴趣FDR，然后正好上了Will的课，系里招了Will过来，然后Michael组里又在读。

[^9]: [Mostly Harmless Econometrics: An Empiricist's Companion](https://press.princeton.edu/books/paperback/9780691120355/mostly-harmless-econometrics)

[^10]:[Large-Scale Inference](https://www.cambridge.org/core/books/largescale-inference/A0B183B0080A92966497F12CE5D12589)


那个时候我在跟Michael头脑风暴想研究课题，一开始Michael给我的题目是做Bag of Little Bootstrap。是他之前做distribution inference的一个想法。当数据分布在很多机器上的时候，这时候你想做bootstrap其实不容易，因为他们的communication cost很高。那我们有没有办法在局部做bootstrap，然后最后再aggregate，做confidence interval。因为当时做distributed inference的时候，大部分还是在考虑estimation，很少人会考虑inference的问题。所以当时它就有一个方法叫Bag of Little Bootstrap，BLB，他们想让我研究一下这个方法的性质。起初我跟他做第一个框架，其实我在推High-Dimensional Edgeworth expansions，跟我现在的研究方向差别很大。


**雷理骅**：我第一个暑假大概花了一两个月的时间读一本非常经典的Edgeworth expansion教材，然后试图去学习那些证明，他们的证明都是假设维度是个常数，但是实际上那个常数其实是指数上升的，所以没有办法直接使用。anyway就是我花了很多时间试图把证明给推广到高维情况。后来推出一些很奇怪结论，比如说它这个dimension是 n的2/27次方的时候，确实能得到一些结果，非常奇怪。当时我也写下来一个大概三四十页的笔记，但是我觉得，好像我也并没有直接想把这篇文章写成一篇paper的。但与此同时，我正好第一年的下半学期我上了(我也不认识这人-锐)的convex optimization ，而同样也是因为final project， 当时我也是想好好地研究一个问题，我接受了一个variance reduction。这个非常漂亮，相当于把统计里面用的variance reduction，其实是control variance，是一个蒙特卡洛里面被研究很多很多的方法，用在了优化里面，然后它就达到了一些很好的性质。于是当时我就在想能不能沿着这个方面做一下，后来我就发现，当时我切入点非常小，我就想证明某一个算法叫做SVRG它能够work for none-strongly convex optimization algorithm。

(SVGR paper: Accelerating Stochastic Gradient Descent using Predictive Variance Reduction. This paper has been highly cited since its publication)


**雷理骅**：原来的paper就是他们理论上只有对strongly convex 目标函数的结果，但是你实际发现效果非常好，即便是non-strongly convex效果也很好。我就在想说有没有办法能证明它对non-strongly convex的结果好？结果发现始终做不出来。但结果很有趣的是最后我发现了一个问题，大家在讨论optimization algorithm的时候，一般来说从一个initial point开始，run 一万步，我去看这一万步之后的convergence rate。但我发现如果把10,000这个数变成一个有某均值的几何随机变量， 就会有一些很奇妙的性质。后来我就通过这个性质设计了一个新的算法，其实就是把SVRG改变了一点点。于是我发现它不仅能对non-strongly convex目标函数可行，并且还能得到一种adaptivity，就是说如果你的目标函数是strongly convex，你能直接达到那个收敛速率，但你不需要知道它是不是需要strongly convex。后来我管这个叫geom-transition。然后我就跟Mike说了这个想法，Mike觉得这个想法非常的有趣。说实话，直到现在我也不能完全解释为什么这个就work。说实话，直到现在我也不能完全解释为什么这个就work。

**统计之都**：是怎么发现的呢？

**雷理骅**：这就类似打竞赛，竞赛的时候会要解决一些很难的题目，所以会去想一些非常奇怪的解法。当时也是，我就想说为了证明这个，我能不能反推，我需要怎么设计这个算法，使得我能得到结果？最后真的是有一天突然就发现了几何随机变量的性质，它用到的性质并不是我们统计熟知的性质，是一个很独特的性质，却很难解释。后来发现了这个性质以后。

**统计之都**：是什么性质还记得吗？

**雷理骅**：是一个非常technical的性质，我感觉很难解释，大概就是说如果你给我一个sequence，我去看它的first order difference，如果说我看的Index是一个geometric random variable，它的first order difference的期望会等于它的最早的点减去它当前点。 这个跟在优化里面，一个叫telescoping的technic，非常相近的一个technic，其实就是当你有类似于对$A_k - A_{k+1}$的表达式，把它们都加起来，就会变成$A_0 - A_{k+1}$。但是在优化里面，$A_{k+1}$导致了很多麻烦，因为$A_{k+1}$其实不存在。
但geometrization可以一定程度上把它变成$A_k$。所以这个很看上去是个很小的工具，但是后来我们发现了它很多的应用，我跟Mike说了以后，于是我们写了第一篇文章，后来很快我们就在想，能不能对non convex优化问题也有用，在当时的时候，当时的state of the art是说对于finite sample 优化问题，非凸问题最好的做法，如果你要最好的准确性的话，还是SGD，或者一些加速SGD算法。理论上的次方数是一直都没有变过，但我们通过这个工具才可以发现可以做得更好。原本一直是，比如说如果你想达到梯度的期望小于等于epsilon，之前的理论速度一直是1/epsilon的四次方， 其他的加速SGD算法只能在一些比较特殊的情况上面提升四次方，但一般情况下它不能提升四次方。而我们当时就通过SVRG和我们这个工具发现了一个10/3次方，这个结果。

**统计之都**：Interesting。

**雷理骅**：很快大家发现，这不是最优的，大家发现三是最优的，这也就发生在我们的论文发出来半年到一年之内，因为大家在这个领域其实真的非常强势。一旦发现这个不是最优的，一旦有了这样一个证据以后，它就会很快意识到，OK，怎么样去move forward。

**统计之都**：对，是的。

**雷理骅**：所以这时候跟Mike，所以当时Mike有大概很长的一段时间，他一直对优化问题很感兴趣，但是他在近几年转向了经济学，那段时间，优化就是他一个主要的方向，就正好跟他契合了，我想既然这个东西这么有趣，我们就一起工作一下。后来做了这样一个非凸问题工作，后来继续在做adaptivity，这个adaptivity就是说限制我们有很多很多算法，他们都work for different rigime，比如说对strongly convex，对non-strongly convex；对high accuracy，对low accuracy；对finite sum，对infinite sum，它们都有不同的algorithm，但实际情况下你永远不知道你在哪个rigime。所以我们在想，能不能设计一个算法，这个算法尽可能少的depends on hyper parameter，使得它能work for all。所以我们就发现最后geometric optimization technic非常的有用，大概我就以这样的方式跟Mike合作了几篇优化领域的文章。

**统计之都**：非常有趣。和丁鹏的因果推断方向的研究又是如何开始的？

**雷理骅**：这个我非常感谢丁鹏，还有和他同期进来的几个教授，包括Avi Feller，Will Fithian，和当时来这边的一个博士后，叫Alexander D'Amour。他们在Berkeley的那几年，他们是Berkeley 因果推断的第一批人。他们就在Berkeley搞了一个因果推断的读书小组。起初也是大家一起来读书。我们当时读了很多课题，比如说第一个学期在读高维因果推断，接下来读了统计推断，读了optimal design，后来读的哲学，实际应用，有一个学期专门是读因果推断的各种有趣的应用，经典的应用。还有一个学期读semi parametrics。在我毕业的学期又读了半参数分析和面板数据。这个其实让我学到很多，其实让我因果推断入门一个最好的方式。因为因果推断我感觉其实是一个很大领域，但其实入门会不是那么的简单。因为在我读博士的时候，因果推断其实并没有那么火。尤其是当你刚开始学potential outcome的时候，会觉得很难理解。但我们当时，丁鹏、Avi Feller，Will FIthian，还有Alexander D'Amour，以及后来Sam Pimentel也加入了这个因果推断的读书小组。其实他们构建了一个非常好的环境。我们其实每周都会有一个人讲一个论文，但我们会有两个小时的时间。其实演讲者并没有很大的压力，他其实只有准备30~40分钟，而另外一个半小时间我们可能都在聊天，一直在讨论。我们会抓住一些点拼命地去讨论，去看为什么要这么做，怎么去论证。比如说为什么我们要考虑finite population analysis，super population 和finite population之间到底有什么区别？我们怎么去理解IPW estimator，怎么去理解ATT、ATE，怎么去理解optical design和randomize design，它们的核心区别，以及怎么去理解各种不同推断框架下面去定义估计量，它们会有什么tricky的地方。所以当时他们构建了一个很好的环境，可以让我们沟通，可以让我们去深入的理解一个问题。在这个过程中，其实我们有连续三个学期，就要讨论一个问题，叫overlap，或者叫positivity。简单来说，在任何一个observational study，或者你想做因果推断，一个必要的条件是说，任何一个人、任何一个加入到你的study里面的人必须得有不小的概率，expose到treatment group和control group。因为如果说有一批人他永远都只会被control，或有些人永远都会opt into the treatment。这时候你就只能通过假设，通过去做一些extrapolation assumption去推断这些人的信息。不然他们的counter factual其实是不存在。

**统计之都**：是的，对。

**雷理骅**：所以我们当时连续三个学期算就在聊这个问题。你看，所有的paper假设positively或者overlap，那到底我们能不能test？到底它有什么implication？就是我们假设overlap，它是不是一个很强的假设？有很多时候observational study，第一个假设就是strong ignorability，第二个假设就是positivity。大家都会花很长时间去justify strong ignorability，但很多时候大家都会忽略positivity。最多给一个就是propensity score的图，去看一下有没有extreme value。那么想，我们能不能很系统地去研究这个问题？于是当时我的合作者Alexander D'Amour他一开始就要想，我们能不能看overlap的一个implication，就假设overlap它能imply什么。如果他有一些passport implication的话，我们就可以通过他的passport implication，可以反推到底overlap assumption有多大可能性。于是我们一起合写了一篇文章，后来发在JOE上。其实后来我们2017年就写出了第二篇文章，到现在都还没有发出来，只放在我的网站上了。其实我们第一篇文章只是在解释它有什么implication，但我们第二篇文章就在说，到底我们能不能检验overlap？我们发现它不仅能检验，并且我们还能做distribution free test。

**统计之都**：Interesting。

**雷理骅**：是一个很奇怪很奇怪的想法，就类似于我们还是可以用任何机器学习算法。但是我们不需要依赖于估计量是对的。它可以inconsistent，它可以特别差。但是我们可以把overlap assumption看成一个原假设。比如说这个propensity score是在0.1~0.9之间，但这是一个非常奇怪的composite原假设，因为它的原假设空间非常大。但我们发现，如果说你能知道这个东西的意义，这个本身它太能被检验，但如果你知道它的implication，也许是可以被检验的。于是我就用了一个很奇怪的想法，就是把这个问题跟很多其他的问题，比如说sequential analysis，rank tests，还有classification联系起来了，用那边的工具得到了这边的一些检验，而且它们是distribution free，而且valid in finite sample。我唯一需要假设就是data IID。

**统计之都**：你需要做sample spliting吗？

**雷理骅**：需要，sample spliting就是为什么可以flexible使用machine learning，但是后面那一步其实就是一个比较非标准的部分。

**统计之都**：非常有趣，我一定要去读一下这篇文章，都还没有读过这篇。

**雷理骅**：也提醒了我们要赶快把它抛出来。目前只有一个在我个人主页上的版本，是因为之前找工作的时候，想提前把它抛出来。

**统计之都**： 博士后的经历你觉得是必要的吗，你的收获又是哪些？因为我听说过一些说法讲，其实你在读博士的时候已经很有名了，当年在job market已经非常受欢迎。所以说在这个基础上，你觉得你的博后的收获又是哪些呢？

**雷理骅**：这是一个很好的问题。其实我在博士快毕业的阶段，我问过很多人这个问题。以及后来在我读博后的时候，很多人问我这个问题。当时我也是在犹豫，是上market（job market），还是去读博后。一开始最直接的契机是，我去找Michael Jordan聊，他非常推荐我去读博后。他说这不是针对你一个人，我会建议我所有的学生如果可能的话都去做一个博后。他的理由是首先你可以拓宽你的network，可以接触更多研究方向，会让你的整个研究变得更成熟，以及你可以在这个过程中，也许有一些新的想法，让你在上market的时候，可能更加能够outstanding。这是最开始的契机，但这个契机可能还不能完全说服我，说实话，于是我就找了很多AP聊。但后来我发现一个很有趣的现象。我会问他你们如果有后悔的事情，后悔的是什么？我从至少五个人那里听到了这样一点，我最后悔的是没有读博士后。

**统计之都**：Interesting。

**雷理骅**：其实更多是其他的，真的是完全没有读博士后。我后来就问他们为什么。他们的点有很多，其中一个点是说，当你从博士到AP的这个时候，你有一个很长的transitioning。这个transitioning可能会耗费你很大的精力，会让你的研究有个断层。博士后期间，因为你相当于多了三年时间或者两年至少。这段时间你可以积累很多其他的想法，这些想法你未必会在，或者提前做。但是等你真正transition到AP的时候，你可以直接把这些拿回来。就真的如果忙得不行了，你至少还是有题目可以做的。尤其是带学生的时候，也许这些问题可以成为你和学生的一个starting project，之后继续再往前推进。但如果没有博士后，如果说你积累的课题不够多的时候，也许一开始会很艰难。

**统计之都**：是的，所以博士后让你的研究变得更加丰富了。

**雷理骅**：但是后来我自己读博士后了以后，我又发现第三个好处。这个好处我觉得我是特别想推荐给大家的，可以让大家也能从这个角度来讲。如果你想进入学术界，其实之后我们并不止步于拿到这个工作，在我们未来，我们的学术生涯可能非常长。而在很多时候，我们需要senior people的支持。比如说我们申请一个基金，我们去申请奖，我们去开会，我们去找合作，这时候如果有senior people的支持，我们会轻松很多。但你想什么样的人会成为你的lifetime support？其实说到底，就是我们的博士生导师，我们博士后导师，和我们的department chair。department chair有可能会换，但是mentor和advisor永远不会变。而在读博士期间，我们有可能有一个或者两个advisor。如果你有一个导师，你如果读博士后，你的lifetime support数量增长一倍，如果是两个导师，你就增长50%，无论如何你都得到了一个显著的量的提升。这个可能会为未来的事业发展也带来很大的好处，无论是从比较实际的这种什么grants奖项这些，还是从未来的emotional support，或者说一些research ideas support上，都会多好多。

**统计之都**：非常有道理！

**统计之都**： 下一个问题就是关于合作的。你的合作者很多，文章也很多，如何在科研中寻找好的合作者？有什么经验？

**雷理骅**：我觉得这个问题可能对senior的人来说更难回答。但其实对年轻人来说，对博士生或者博士后来说，其实没有那么难的。原因是当我们找合作者的时候，我们很多找的合作者本身就比我们senior了。而他们愿意跟我们合作，其实已经是一个很好的信号了。所以这个时候往往我们找到很多的合作，其实很多时候是质量很高，当然也有例外。但我觉得，基本上如果这个人他对待研究比较认真，他有他自己的很明确的taste，并且在你合作的时候，你们能比较平等地对待彼此，我觉得这已经是个很好的合作者了。

因为从学生角度来说，我们更多的是在做合作过程中去学习更senior的一些人思维跟思考问题的方式。所以我觉得这个倒没有必要特别注意什么。其实主要就是，你去找一个你觉得你会尊重，和你会想成为的人，试图去找合作者。并且如果他是一个对人比较友善，对人比较平等的这样的合作者，整体来说我认为都没有问题。


**统计之都**：在选择研究方向的时候，你是会更喜欢选择一些有开创性的挑战性的题目呢，还是会选择一些可能看起来挑战性不高，但是也会有一定意义的，肯定能做出来的题目呢？

**雷理骅**：这是个好问题。在大部分选题的时候，其实我会选择一个相对比较简单的切入点。至少让我进入到这个领域，了解这个领域的问题和它的难点。但接下来，整体上我会比较倾向于一些比较有挑战性的问题，但至于它能不能做出来，其实不好说。因为当你知道的时候，它就一定可以做出来。所以我觉得整体来说，我会去尝试那些有挑战的问题。但是我用来对冲风险的方式，就是我不在一棵树上吊死，我可能同时在想两个或者三个课题。这可能也跟我研究的风格有一些关系。就像我刚才说的，因为我比较喜欢这种finite sample或者distribution free。就在于它往往难在想到那个idea，但是idea到了以后，其实无论是证明，还是编程，还是实际应用都没有那么地难。所以我就会给自己同时两到三个项目在想。如果说真的有一块就很长时间想不出来，我就把它舍了，我就不再继续摸索。但是我会在一个地方记下来，记下来我现在所处的点，以及我接下来想解决，但未能解决的点，也许以后还能revisit。但是我会觉得，这时候你放弃它也没关系，因为你与此同时还有一到两个别的，所以就这个过程，我觉得如果把整个节奏调整好了以后，就会还比较开心。任何时候你肯定会有比较沮丧的时候，因为怎么都想不出来。但是你到另外一个层面，也许用有一些新的想法。

**统计之都**：任何一个研究领域都有其开始，发展，成熟，衰落的过程。你是如何应对你的研究领域的变化的？

**雷理骅**：这是很好的问题。我觉得现在是一个统计非常火的时期，所以任何一个领域都会发展得非常快。像因果推断，在几年前我们刚开学的时候，那时候人还很少。现在可以说是，大家都会在或多或少做一些因果推断。我应对这个的方式是，一开始在这个领域发展的时候，我会试图去多跟这个领域来沟通，去读最新的论文。因为那时候还能跟得上，因为论文不多，所以我就会尽量地去选一些比较有开创性的论文去读，看那边还有什么遗留的问题，以及大方向上我们还有什么急需解决的问题。所以当时我做FDR，一个大方向上是说，在应用里面，在很多基因数据里面，我们有大量的side information。但是已有的FDR方法并不能有效地用到这些side information。

所以这就是一个契机，我觉得OK这是一个方向，我就要利用我现在可能已有的一些想法，我试图往那边去解决那些问题。但很快当一个领域逐渐变得成熟以后，又发现论文会变得越来越多，多到你不可能去follow。在这个时候就只能说，尽可能地去选择一些你现在已经了解的人，或者一些在引领这个领域发展的人的论文读一读，对这个领域的发展速度稍微有一点点直观的感受。如果你觉得这个领域发展速度还可以接受，并且你还愿意在里面继续推进前沿的发展，我觉得就可以继续做。但有时候我会觉得这个领域发展太快了，快到我已经无法follow了。比如说conformal inference就是一个点。发展太快了，一开始我说是，可以把这里所有paper都读一遍，当然这个有点夸张，因为毕竟也有二十多年的历史，其实只是没有被统计的人所发现。但至少我可以说我刚认识的时候，我可以说我对这个领域大部分论文都比较了解。但是很快就发现，可能一年有几十篇甚至上百篇paper出来了，这时候我就会想另辟蹊径，去做一些，就在红海和蓝海里面，或者更相当于是一个蓝海，就看目前还有什么大的问题是急需解决的，我的专业知识有没有可能解决。这个是我觉得一个大方向。当然我可能说得比较抽象，具体来说我觉得这是一个作为学术界的人终身要问的问题，是怎么去应对一个领域的，在不同时期你该如何选择，我觉得我还在仔细地思考这个问题。



## 3. 未来规划与其他问题

**统计之都**： 你的未来的研究方向？

**雷理骅**：首先会继续一些现在正在做的工作，比如说Conformal Inference，还有一些试图解决的问题。然后因果推断是我接下来一个比较重点的研究方向。因为我现在进入到了经济这个领域，我会做更多的关于因果推断和计量经济学。现在计量也是一个非常广的领域，大家在思考，如何把机器学习有效地用在计量。而大家在前面的十年里面，大家已经发现，可以把机器学习当做一种好的预测算法，然后去看一个好的Prediction 怎么去能带来好的Inference。但现在在计量领域里面，其实大家更加ambitious，大家想看，机器学习能不能在其他的方面，以其他的方式产生效用。所以这也是我未来的一个方向之一。另外我现在也是在一个transition的过程中，我有点想做一些新的领域。但这个新的领域是什么？我现在还没有一个很好的想法，也许两年之后能给出一个更好的答案。


**统计之都**： 做AP之后研究心态是否有所变化？

**雷理骅**：研究心态方向方面不会有太大变化。Good research is good research，整个研究的流程还是会一样。当然会有更多的牵涉到基金或者带学生，这些对研究的方式会稍微产生一些影响。但目前的我的预期是，不会发生太大的变化。

**统计之都**：初心不改。

**雷理骅**：对。


**统计之都**： 如何保持旺盛的精力？

**雷理骅**：我觉得一般而言，就是，keep curiosity。我经常会说的，但这可能跟你最后一个问题有关，我们生活就永远都是一个exploratation-exploitation tradeoff。我们知道，如果了解过bandit literature或者online learning，我知道永远都要做一个 Epsilon-Greedy person。在任何时候，你都需要留出一些去探索。因为这个探索可能带来的，我们知道在论文里面它会告诉我们，regret会很小。但是我会更倾向于更positive的方式来说，它会给你带来更多的reward。

**统计之都**：对，所以focus on那些reward，就是做研究带给我们的mental reward，这个是帮助你持续走下去的东西。

**雷理骅**：尤其是exploration带来的reward。Exploration就是说你去接受你可能并没有那么感兴趣，或者你现在并没有很了解的领域。在这个过程中，也许某一天它就成为了你的研究领域。而我之前的经历，其实很大程度上就证明了这一点。因为无论是包括multiple testing，因果推断，还是网络分析，还是优化，都是因为一些机缘巧合，在探索的过程中发现我对这个感兴趣。而且跟我在进入博士这阶段中，我预期我会成为的那个样子，其实相距很远。 


**统计之都**： 对于想要学习统计和机器学习的学生的建议?

**雷理骅**：我觉得第一个建议就是我刚才说的，exploratation-exploitation tradeoff，尤其是在刚刚接触研究的时候，前几年多花时间在探索上，多花时间去听讲座，听专题课程，跟人聊，这些人不仅限于统计圈子里的人，也可以是别的应用圈子里的人。如果研究基金允许的话，多接触各种各样的人，去了解他们的研究兴趣。有可能听不懂他们做的东西，就会觉得沮丧，其实很多时候是一个exposure effect，你可能第一次觉得词很陌生。但是很神奇的是，当你听这个词听五次六次的时候，你不了解，你也觉得你了解了。这个效果它是真实存在的。它会让你更快地融入到一个新的领域，更快地去熟悉这个领域里面一些有趣的问题，我觉得这是一个大的建议。但另一方面永远就是push自己不要push太厉害。有的时候我们作为博士生，我们其实是有很多flexiblity的。当你发现一个领域不适合自己的时候，就及时转换。除非你已经到了job market上，除非你已经花了很多年，沉没成本非常高。不然任何时候你都可以去转变自己的方向，可能会获得更多科研的愉悦感，找到最适合自己的那个。
