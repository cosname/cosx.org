---
title: 数据科学中的“数据智慧”
date: '2015-05-21T14:20:24+00:00'
author: 郁彬
categories:
  - 推荐文章
  - 统计之都
slug: the-data-wisdom-for-data-science
forum_id: 419082
meta_extra: "译者：吕翔、张心雨；审校：施涛、高涛；编辑：王小宁"
---

原文链接：[http://www.odbms.org/2015/04/data-wisdom-for-data-science/](http://www.odbms.org/2015/04/data-wisdom-for-data-science/)

**本文得到了原英文作者[郁彬](http://www.stat.berkeley.edu/~binyu/Site/Welcome.html)的授权同意，由吕翔和张心雨翻译、[施涛](http://blog.cos.name/taoshi/)和高涛审校。感谢他们的支持和帮助。**

在大数据时代，学术界和业界的大量研究都是关于如何以一种可扩展和高效率的方式来对数据进行储存，交换和计算（通过统计方法和算法）。这些研究领域无疑非常重要，然而，只有当我们对数据智慧（Data Wisdom）也给予同等程度的重视时，大数据（或者小型数据）才能被转换为真正的知识和有用的，可被采纳的信息。换而言之，我们要认识到必须拥有足够数量的数据才有可能对复杂度较高的问题给出较可靠的答案。“数据智慧”对于我们从数据中提取有效信息和确保没有误用或夸大原始数据是至关重要的。

“数据智慧”一词是我对应用统计学核心部分的重新定义。这些核心部分在伟大的统计学家（或者说是数据科学家）John W. Tukey 和 Geogre Box 的文章中有详细阐述。

<!--more-->

[http://projecteuclid.org/euclid.aoms/1177704711](http://projecteuclid.org/euclid.aoms/1177704711)

[http://www.tandfonline.com/doi/abs/10.1080/01621459.1976.10480949#.VR2_eWYhByU](http://www.tandfonline.com/doi/abs/10.1080/01621459.1976.10480949#.VR2_eWYhByU)


要让统计圈以外的人了解，“数据智慧”是非常必要的重命名，因为它比“应用统计学”这个术语能更好概括其核心成分。 这样一个有信息量的名称可以使人们意识到应用统计作为数据科学一部分的重要性。

引用维基百科中对“智慧“这一词条解释的第一句话，我想说：

“数据智慧”是 **将领域知识、数学和方法论与经验、理解、常识、洞察力以及良好的判断力相结合，思辨性地理解数据和依据数据做决策的一种能力。**

“数据智慧”是数学、自然科学和人文主义这三方面能力的融合，是科学和艺术的结合。在缺乏有实践经验者的指导下，个人很难仅仅靠从读书中获得“数据智慧”， 想要学习它的最好方法就是和拥有它的人一起共事。当然，我们也可以通过问答方式来帮助形成和培养“数据智慧”的能力。我这里有10个基本问题，我鼓励人们在开始从事数据分析项目或者在其过程中可以经常问问自己。这些问题刚开始时是按照一定顺序排列的，但是在不断重复的数据分析过程中，这个顺序完全可以被打乱。

这些问题也许无法详尽彻底的解释“数据智慧”，但是它们体现了“数据智慧”的一些特点

# 1.要回答的问题

数据科学的问题最开始往往来自于统计学或者数据科学以外的学科。例如，神经科学中的一个问题：大脑是如何工作的？或银行业中的一个问题：该对哪组顾客推广新服务？要解决这些问题，统计学家必须要与该领域的专家进行合作。这些专家会提供有助于解决问题的领域知识，早期研究成果，更广阔的视角，甚至可能是对该问题的重新定义。与这些（往往可能很忙）专家建立联系需要很强的人际交流技巧。

而这种交流对于数据科学项目的成功是必不可少的。在有充足数据来源的情况下，经常发生情况的是在数据收集前要回答的问题还没有被精确定义。正如 Tukey 所说的那样：**“我们在‘探索性数据分析（Exploratory Data Analysis）’的游戏中。”** 我们寻找需要回答的问题，然后不断重复统计调查过程（就像上文提到的 George Box 的文章中所述）。由于误差的存在，我们谨慎的避免对于数据中出现的模式进行过度拟合。例如，当同一份数据既被用于问题的建模又被用于问题的验证时，过度拟合就会发生。一条黄金准则就是将数据分割，在分割时考虑到数据潜在的结构（如相关性，聚类性，异质性）使分割后的每部分数据都对原始数据具有代表性。用其中一部分来探索问题，而另一部分用来通过预测或者建模来回答问题。

# 2.数据收集

什么样的数据与（1）中要回答的问题最相关？

实验设计（统计学的一个分支）和主动学习（机器学习的一个分支）中的方法对解决这个问题有所帮助。即使是在数据已经收集好了以后，考虑这个问题也是很有必要的。因为对理想的数据收集机制的理解可以暴露出实际数据收集过程的缺陷，能够指导下一步分析的方向。

下面的问题会有所帮助：

数据是如何收集的？ 在哪些地点？在什么时间段？谁收集的？用什么设备收集的？中途操作人员和设备被更换过吗？

总之，试着想象自己亲身在数据收集现场。

# 3.数据含义

数据中的某个数值代表了什么含义？它测量了什么？它是否测量要测量的？哪些环节可能会出差错？在哪些统计假设下可以认为数据收集没有问题？（对数据收集过程的详细了解在这会很有帮助。）

# 4.相关性

收集来的数据能完全或部分地回答要研究的问题吗？如果不能，还需要收集什么其他数据？第2个问题中提到的要点在此处同样受用。

# 5.问题转化

如何将（1）中的问题转化成一个数据相关的统计问题，使之能够很好回答与原始问题呢？有多种转换方式吗？比如，我们可以把问题转换成一个与统计模型有关的预测问题或者统计推断问题吗？在选择模型前，列出将每一种能解决与实质性问题的转化方式的优点和缺点。

# 6.可比性

各数据单元是否是可比的，或经过标准化处理而可视为可交换的？苹果和橘子是否被组合在一起了？数据单元是否相互独立？两列数据是不是同一个变量的副本？

# 7.可视化

观察数据（或其子集），制作一维或二维图表，并检验这些的数据的统计量。询问数据范围是什么？数据正常吗？是否有缺失值？多使用颜色和动态图，注意有意料之外的情况记住，我们大脑皮层的30%都是用来处理图像的，所以可视化在挖掘数据模式和特殊情况时非常有效。通常情况，为了找到大数据的模式，可视化在建立某些模型之后使用最有用，比如，计算残差并进行可视化展示。

# 8.随机性

统计推断的概念，比如p值和置信区间，都依赖于随机性。那数据中的随机性是什么含义呢？我们要对统计模型的随机性尽量明确地定义。哪些所研究的领域中知识支持所用统计模型中的随机性的描述？一个表现统计模型中随机性的最好例子，就是因果关系分析中 Neyman-Rubin 的随机分组原理（在AB检验中也有使用）。

# 9.稳定性

你会使用哪些现有的方法？不同的方法会得出同一个定性的结论吗？对数据进行随机扰动，例如，可以通过添加噪声或二次抽样实现（一般来说，应确定二层样本有原样本的结构，如相关性，聚类特性和异质性，这样二层样本能较好地代表原始数据）。结论依然成立吗？我们应该只相信那些能通过稳定性检验的方法，稳定性检验简单易行，能够抗过度拟合和过多假阳性发现，具有可重复性（要了解关于稳定性重要程度的更多信息，请参看[文章](http://projecteuclid.org/euclid.bj/1377612862)）。

可重复性研究最近在科学界中吸引了很多注意，请参照[《Nature》特刊](http://www.nature.com/nature/focus/reproducibility/)。《Science》的主编 Marcia McNutt 指出“实验再现是科学家用以增加结论信度的一种重要方法”。同样，商业和政府实体也应该要求从数据分析中得出的结论，当用新的同质数据检验时是可再重复的。

# 10.结果验证

人们怎样能知道数据分析是不是做的好呢？衡量标准是什么？可以考虑用其他类型的数据或者先验知识来衡量有效性，不过可能需要收集新的数据以确认结果的有效程度。

在数据分析时还有许多其他问题要考虑，但我希望上面的这些问题能使你对如何获取“数据智慧”产生一点感觉。作为一个统计学家，这些问题的答案需要在统计学之外获取。要找到可靠的答案，有效的信息源包括“死的”（如科学文献、报告和书籍）和“活的”（如人）。出色的人际交流技能使得寻找正确信息源的过程简单了许多，即使是在寻求“死的”信息源的过程中也是这样。因此，为了获取充足的信息，人际交流技能将更加重要，因为在我的经验中，知识渊博的人通常是你最好的指路。
