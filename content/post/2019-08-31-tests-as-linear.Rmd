---
title: "翻译：常见统计检验的本质都是线性模型（或：如何教统计学）"
author: "Jonas Kristoffer Lindeløv"
date: "2019-08-31"
categories:
  - 推荐文章
  - 统计理论
  - 统计应用
tags:
  - 方法论
  - 统计学
meta_extra: "译者：黄俊文、校对：蔡占锐，谢益辉，黄湘云、编辑：孙腾飞、任焱"
slug: common-tests-as-linear-models
lang: "zh-Hans"
forum_id: 420930
output: 
  html_fragment:
    df_print: default
    number_sections: yes
    self_contained: no
    toc: no
---
<link rel="stylesheet" type="text/css" href="include/style.css">

<!-- From https://stackoverflow.com/a/37839683/1297830 -->
<link rel="stylesheet" type="text/css" href="include/hideOutput.css">
<script src="include/hideOutput.js"></script>

```{r echo=FALSE}
# Options for building this document
knitr::opts_chunk$set(
  dev = "svg",
  fig.height = 4,
  fig.width = 6,
  fig.align = "center",
  message = FALSE,
  warning = FALSE
)

# To show tables.
print_df <- function(D,
                     decimals = 4,
                     navigate = FALSE) {
  DT::datatable(
    mutate_if(D, is.numeric, round, decimals),
    rownames = FALSE,
    options = list(
      searching = FALSE,
      lengthChange = FALSE,
      ordering = FALSE,
      autoWidth = TRUE,
      bPaginate = navigate,
      bInfo = navigate,
      paging = navigate
    )
  )
}

# packages only available on Github
remote_pkgs = c(headR = 'jumpingrivers', patchwork = 'thomasp85')

lapply(c(
  'car', 'broom', 'DT', 'knitr', 'tidyverse', 'sm', 'rprojroot', 'remotes'
  ), function(pkg) {
    if (system.file(package = pkg) != '') return()
    repo = remote_pkgs[pkg]
    if (is.na(repo)) install.packages(pkg) else {
      remotes::install_github(paste(repo, pkg, sep = '/'))
    }
  }
)
```

> 本文翻译自 [Jonas Kristoffer Lindeløv](https://lindeloev.net/) 的 [Common statistical tests are linear models (or: how to teach stats)](https://lindeloev.github.io/tests-as-linear/)，翻译工作已获得原作授权。

本文将常见的参数和“非参”数检验统一用线性模型来表示，在同一个框架下， 我们可以看到不同检验之间的许多相似之处，极富思考性和启发性。点击链接可获得一份 [PDF 电子版](linear_tests_cheat_sheet.pdf) 或 [HTML 网页版](linear_tests_cheat_sheet.html)。

[![linear-tests-cheat-sheet](linear_tests_cheat_sheet.png)](linear_tests_cheat_sheet.pdf)


# 常见检验的简洁本质

大部分常见的统计模型（t 检验、相关性检验、方差分析（ANOVA）、卡方检验等） 是线性模型的特殊情况或者是非常好的近似。这种优雅的简洁性意味着我们学习起来不需要掌握太多的技巧。具体来说，这都来源于大部分学生从高中就学习的模型：$y = a \cdot x + b$。 然而很不幸的是，统计入门课程通常把各种检验分开教学，给学生和老师们增加了很多不必要的麻烦。在学习每一个检验的基本假设时，如果不是从线性模型切入，而是每个检验都死记硬背，这种复杂性又会成倍增加。因此，我认为先教线性模型，然后对线性模型的一些特殊形式进行改名是一种优秀的教学策略，这有助于更深刻地理解假设检验。线性模型在频率学派、贝叶斯学派和基于置换的U检验的统计推断之间是相通的，对初学者而言，从模型开始比从 P 值、第 I 类错误、贝叶斯因子或其它地方更为友好。

在入门课程教授“非参”数检验的时候，可以避开 [骗小孩](https://en.wikipedia.org/wiki/Lie-to-children) 的手段，直接告诉学生“非参”检验其实就是和秩相关的参数检验。对学生来说，接受秩的概念比相信你可以神奇地放弃各种假设好的多。实际上，在统计软件 [JASP](https://jasp-stats.org/) 里，“非参”检验的贝叶斯等价模型就是使用 [潜秩](https://arxiv.org/abs/1712.06941)（Latent Rank）来实现的。频率学派的“非参”检验在样本量 $N > 15$ 的时非常准确。

![Path to success](https://www.picsellmedia.com/wp-content/uploads/2017/01/shutterstock_336913772.jpg)

在[来源](#links)和[教材](#course)两章节，有很多类似（尽管更为散乱）的材料。我希望你们可以一起来提供优化建议，或者直接在 [Github](https://github.com/lindeloev/tests-as-linear) 提交修改。让我们一起来使本文章变得更棒！

# 设置和示例数据

如果你想查看函数和本笔记的其它设置的话，可以展开这片代码查看：

<div class='fold s'>
```{r, echo=FALSE, R.options=list(tidyverse.quiet = TRUE), message=FALSE}
# Load packages for data handling and plotting
library(tidyverse)
library(patchwork)
library(broom)

# Reproducible "random" results
set.seed(40)

# Generate normal data with known parameters
rnorm_fixed <- function(N, mu = 0, sd = 1)
  scale(rnorm(N)) * sd + mu

# Plot style.
theme_axis <- function(P,
                       jitter = FALSE,
                       xlim = c(-0.5, 2),
                       ylim = c(-0.5, 2),
                       legend.position = NULL) {
  P <- P + theme_bw(15) +
    geom_segment(
      x = -1000, xend = 1000,
      y = 0, yend = 0,
      lty = 2, color = "dark gray", lwd = 0.5
    ) +
    geom_segment(
      x = 0, xend = 0,
      y = -1000, yend = 1000,
      lty = 2, color = "dark gray", lwd = 0.5
    ) +
    coord_cartesian(xlim = xlim, ylim = ylim) +
    theme(
      axis.title = element_blank(),
      axis.text = element_blank(),
      axis.ticks = element_blank(),
      panel.border = element_blank(),
      panel.grid = element_blank(),
      legend.position = legend.position
    )

  # Return jittered or non-jittered plot?
  if (jitter) {
    P + geom_jitter(width = 0.1, size = 2)
  }
  else {
    P + geom_point(size = 2)
  }
}
```
</div>


一开始，我们简单点，使用三组正态分布数据，且整理为宽（`a`、`b`、`c`）和长（`value`、`group`）格式：


```{r}
# Wide format (sort of)
# y = rnorm_fixed(50, mu=0.3, sd=2)  # Almost zero mean.
y <- c(rnorm(15), exp(rnorm(15)), runif(20, min = -3, max = 0)) # Almost zero mean, not normal
x <- rnorm_fixed(50, mu = 0, sd = 1) # Used in correlation where this is on x-axis
y2 <- rnorm_fixed(50, mu = 0.5, sd = 1.5) # Used in two means

# Long format data with indicator
value <- c(y, y2)
group <- rep(c("y1", "y2"), each = 50)
```


# Pearson 相关性和 Spearman 相关性 {#correlation}

## 理论：作为线性模型

模型：$y$ 的形式是一个斜率（$\beta_1$）乘以 $x$ 加上一个截距（$\beta_0$），也就是一条直线。

$y = \beta_0 + \beta_1 x \qquad \mathcal{H}_0: \beta_1 = 0$

以上模型，实际上是我们熟悉的旧公式 $y = ax + b$ （这里书写顺序变为 $y = b + ax$）的一个更数学化的表达。在 R 软件里面，我们比较懒，所以写成了 `y ~ 1 + x`，R 对此理解为 $y = 1\times\mathrm{数} + x\times\mathrm{另一个数}$，而且，t 检验，线性回归等等都只是去寻找能够最好地预测 $y$ 的数字。

无论你怎么书写，截距（$\beta_0$）和斜率（$\beta_1$）都可以确定一条直线： 

<div class="fold s">
```{r}
# Fixed correlation
D_correlation <- data.frame(MASS::mvrnorm(30,
  mu = c(0.9, 0.9),
  Sigma = matrix(c(1, 0.8, 1, 0.8), ncol = 2),
  empirical = TRUE
)) # Correlated data

# Add labels (for next plot)
D_correlation$label_num <- sprintf("(%.1f,%.1f)", D_correlation$X1, D_correlation$X2)
D_correlation$label_rank <- sprintf("(%i,%i)", rank(D_correlation$X1), rank(D_correlation$X2))

# Plot it
fit <- lm(I(X2 * 0.5 + 0.4) ~ I(X1 * 0.5 + 0.2), D_correlation)
intercept_pearson <- coefficients(fit)[1]

P_pearson <- ggplot(D_correlation, aes(x = X1 * 0.5 + 0.2, y = X2 * 0.5 + 0.4)) +
  geom_smooth(method = lm, se = FALSE, lwd = 2, aes(colour = "beta_1")) +
  geom_segment(
    x = -100, xend = 100,
    y = intercept_pearson, yend = intercept_pearson,
    lwd = 2, aes(color = "beta_0")
  ) +
  scale_color_manual(name = NULL, values = c("blue", "red"), 
                     labels = c(bquote(beta[0] * " (intercept)"), 
                                bquote(beta[1] * " (slope)")))

theme_axis(P_pearson, legend.position = c(0.4, 0.9))
```
</div>

这通常被称为回归模型，而且当右边有多个 $\beta$ 和自变量相乘的时候，它被扩展为多元回归。以下的所有模型，从[单样本 t 检验](#t1)到[双因素方差分析](#anova2)，都是在这个设定下的特殊形式，不多不少。

顾名思义，**Spearman 秩相关系数**就是 $x$ 和 $y$ 的秩变换后的**Pearson 相关系数**：

$\mathrm{rank}(y) = \beta_0 + \beta_1 \cdot \mathrm{rank}(x) \qquad \mathcal{H}_0: \beta_1 = 0$

很快我就会介绍[秩](#rank)这一个概念。现在，注意到线性模型的相关系数就是等价于“真正的” Pearson 相关系数，但是 P 值是近似值，这个近似值适用于 $N>10$，并且在 $N > 20$ 的情况下[几乎完美](simulations/simulate_spearman.html)。

很多学生都没有意识到这么漂亮和神奇的等价关系！对它们带上数据标签来可视化，我们可立刻看到这一秩转换过程：

<div class="fold s">
```{r, fig.width=8, figh.height=7}
# Spearman intercept
intercept_spearman <- coefficients(lm(rank(X2) ~ rank(X1), D_correlation))[1]

# Spearman plot
P_spearman <- ggplot(D_correlation, aes(x = rank(X1), y = rank(X2))) +
  geom_smooth(method = lm, se = FALSE, lwd = 2, aes(color = "beta_1")) +
  geom_text(aes(label = label_rank), nudge_y = 1, size = 3, color = "dark gray") +
  geom_segment(
    x = -100, xend = 100,
    y = intercept_spearman, yend = intercept_spearman,
    lwd = 2, aes(color = "beta_0")
  ) +
  scale_color_manual(name = NULL, values = c("blue", "red"), 
                     labels = c(bquote(beta[0] * " (intercept)"), 
                                bquote(beta[1] * " (slope)")))

# Stich together using patchwork
(theme_axis(P_pearson, legend.position = c(0.5, 0.1)) + 
    geom_text(aes(label = label_num), nudge_y = 0.1, size = 3, color = "dark gray") +
    labs(title = "         Pearson"))

(theme_axis(P_spearman, xlim = c(-7.5, 30), ylim = c(-7.5, 30), 
              legend.position = c(0.5, 0.1)) + 
     labs(title = "         Spearman"))
```
</div>


## 理论：秩转换 {#rank}

对于一串数字，秩（rank）意思是使用它们的排序号来替换它们（第 1 最小的，第 2 最小的，第 3 最小的，以此类推）。因此 `rank(c(3.6, 3.4, -5.0, 8.2))` 的秩转换结果是 `3, 2, 1, 4`。从上面的图形里看出来了吗？符号秩是一样的，先根据绝对值排序，再添加上数值前面的符号。所以上面的符号秩是 `2, 1, -3, 4`。用代码表示如下：

```{r}
signed_rank = function(x) sign(x) * rank(abs(x))
```

我希望我说秩很容易理解的时候没有冒犯到其他人。然而，这就是你转换大部分“非参”数检验到它们的对应参数检验所要做的全部事情！一个重要的推论是，很多“非参”检验和它们的对应参数检验版本都有一致的参数：均值、标准差、方差齐次性等等 ---- 区别在于它们是在秩转换后的数据上计算的。这是为什么我把“非参”用引号包起来。


### R 代码：Pearson 相关系数

在 R 里运行这些模型再容易不过了。它们产生相同的 `p` 值和 `t` 值，但是这里有个问题：`lm` 返回*斜率*，尽管它通常比*相关系数* *r* 更容易理解和反映了更多信息，但你依然想得到 *r* 值。幸运地，如果 `x` 和 `y` 有相同的标准差，斜率就会变成 `r`。所以，在这里我们使用 `scale(x)` 使得 $SD(x) = 1.0$ 和 $SD(y) = 1.0$：


```{r}
a <- cor.test(y, x, method = "pearson") # Built-in
b <- lm(y ~ 1 + x) # Equivalent linear model: y = Beta0*1 + Beta1*x
c <- lm(scale(y) ~ 1 + scale(x)) # On scaled vars to recover r
```

结果：

```{r, echo=FALSE}
at <- tidy(a)
bt <- tidy(b)[2, ] # Only slope
bt$conf.low <- confint(b)[2, 1]
bt$conf.high <- confint(b)[2, 2]

ct <- tidy(c)[2, ] # Only slope
ct$conf.low <- confint(c)[2, 1]
ct$conf.high <- confint(c)[2, 2]

# Merge and print nicely
df <- bind_rows(at, ct, bt) %>%
  mutate(model = c("cor.test", "lm scaled", "lm")) %>%
  rename(
    t = statistic,
    r = estimate
  ) %>%
  select(model, p.value, t, r, conf.low, conf.high)

print_df(df)
```

<div class="fold o">
```{r, echo=FALSE, results='hold'}
a
summary(b)
summary(c)
```
</div>

置信区间没有完全一致，但是非常相近。


### R 代码：Spearman 相关系数

注意，我们可以把斜率解释为：对于每一 $x$ 的秩的变化，所获得的相应 $y$ 的秩的变化。我认为这个数字非常有趣。然而，截距更难解释，因为它定义在 $\mathrm{rank}(x) = 0$ 的时候，然而这其实是不可能的，因为 x 是从 1 开始的。

查看相同的 `r` （即这里的 `rho`） 和 `p`：

```{r, results='hold'}
# Spearman correlation
a <- cor.test(y, x, method = "spearman") # Built-in
b <- lm(rank(y) ~ 1 + rank(x)) # Equivalent linear model
```

让我们看一下结果：

```{r, echo=FALSE}
df <- data.frame(
  model = c("cor.test", "lm"),
  p.value = c(a$p.value, tidy(b)$p.value[2]),
  rho = c(a$estimate, b$coefficients[2])
)

print_df(df)
```

<div class="fold o">
```{r, echo=FALSE, results='hold'}
a
summary(b)
```
</div>


# 单均值
## 单样本 t 检验和 Wilcoxon 符号秩检验 {#t1}
### 理论：作为线性模型

**t 检验**模型：单独一个数字来预测 $y$。

$y = \beta_0 \qquad \mathcal{H}_0: \beta_0 = 0$

换句话说，这是我们所熟悉的 $y = \beta_0 + \beta_1*x$，其中最后一项消失了，因为 $x$ 不存在了（等价地，$x=0$。见下方左图）。

以上模型，一旦用 $y$ 的[符号秩](#rank)来替换了 $y$ 本身（见下方右图），就和**Wilcoxon 符号秩检验**非常相近。

$signed\_rank(y) = \beta_0$

这个近似对于样本量大于 14 的情况已足够好，对于大于 50 的情况下[接近完美](simulations/simulate_wilcoxon.html)。

<div class="fold s">
```{r fig.width=7, fig.height=5}
# T-test
D_t1 <- data.frame(
  y = rnorm_fixed(20, 0.5, 0.6),
  x = runif(20, 0.93, 1.07)
) # Fix mean and SD

P_t1 <- ggplot(D_t1, aes(y = y, x = 0)) +
  stat_summary(
    fun.y = mean, geom = "errorbar",
    aes(ymax = ..y.., ymin = ..y.., color = "beta_0"), lwd = 2
  ) +
  scale_color_manual(
    name = NULL, values = c("blue"),
    labels = c(bquote(beta[0] * " (intercept)"))
  ) +
  geom_text(aes(label = round(y, 1)), nudge_x = 0.2, size = 3, color = "dark gray") +
  labs(title = "         T-test")

# Wilcoxon
D_t1_rank <- data.frame(y = signed_rank(D_t1$y))

P_t1_rank <- ggplot(D_t1_rank, aes(y = y, x = 0)) +
  stat_summary(
    fun.y = mean, geom = "errorbar",
    aes(ymax = ..y.., ymin = ..y.., color = "beta_0"), lwd = 2
  ) +
  scale_color_manual(
    name = NULL, values = c("blue"),
    labels = c(bquote(beta[0] * " (intercept)"))
  ) +
  geom_text(aes(label = y), nudge_x = 0.2, size = 3, color = "dark gray") +
  labs(title = "         Wilcoxon")

# Stich together using patchwork
theme_axis(P_t1, ylim = c(-1, 2), legend.position = c(0.6, 0.1))
theme_axis(P_t1_rank, ylim = NULL, legend.position = c(0.6, 0.1))
```
</div>


### R 代码：单样本 t 检验
尝试运行以下 R 代码，确认线性模型（`lm`）和内置的 `t.test` 产生相同的 $t$、$p$、$r$。`lm` 的输出没有置信区间，但是你可以用 `confint(lm(...))` 来确认结果也是相同的：

```{r}
# Built-in t-test
a <- t.test(y)

# Equivalent linear model: intercept-only
b <- lm(y ~ 1)
```

结果：

```{r, echo=FALSE}
df <- data.frame(
  model = c("t.test", "lm"),
  mean = c(a$estimate, b$coefficients),
  p.value = c(a$p.value, tidy(b)$p.value),
  t = c(a$statistic, tidy(b)$statistic),
  df = c(a$parameter, b$df.residual),
  conf.low = c(a$conf.int[1], confint(b)[1]),
  conf.high = c(a$conf.int[2], confint(b)[2])
)
print_df(df)
```

<div class="fold o">
```{r, echo=FALSE, results='hold'}
a
summary(b)
```
</div>



### R 代码：Wilcoxon 符号秩检验
除了一致的 `p` 值，`lm` 也提供了符号秩均值，我发现这个数字非常有信息量。

```{r, results='hold'}
# Built-in
a <- wilcox.test(y)

# Equivalent linear model
b <- lm(signed_rank(y) ~ 1) # See? Same model as above, just on signed ranks

# Bonus: of course also works for one-sample t-test
c <- t.test(signed_rank(y))
```

结果：

```{r, echo=FALSE}
df <- data.frame(
  model = c("wilcox.test", "lm", "t.test"),
  p.value = c(a$p.value, tidy(b)$p.value, c$p.value),
  mean_rank = c(NA, tidy(b)$estimate, c$estimate)
)
print_df(df)
```

<div class="fold o">
```{r, echo=FALSE, results='hold'}
a
summary(b)
c
```
</div>



## 配对样本 t 检验和 Wilcoxon 配对组检验 {#tpair}
### 理论：作为线性模型
**t 检验**模型：一个数字（截距）来预测组间之差。

$y_2-y_1 = \beta_0 \qquad \mathcal{H}_0: \beta_0 = 0$

这意味着只有一个 $y = y_2 - y_1$ 需要预测，而且它变成了对于组间之差的[单样本 t 检验](#t1)。因此可视化效果和单样本 t 检验是相同的。冒着过度复杂化简单作差的风险，你可以认为这些组间之差是斜率（见图的左半部分），我们也可以用 y 的差来表达（见图的右半部分）：

<div class="fold s">
```{r, fig.width=7, fig.height=3}
# Data for plot
N <- nrow(D_t1)
start <- rnorm_fixed(N, 0.2, 0.3)
D_tpaired <- data.frame(
  x = rep(c(0, 1), each = N),
  y = c(start, start + D_t1$y),
  id = 1:N
)

# Plot
P_tpaired <- ggplot(D_tpaired, aes(x = x, y = y)) +
  geom_line(aes(group = id)) +
  labs(title = "          Pairs")

# Use patchwork to put them side-by-side
theme_axis(P_tpaired)
theme_axis(P_t1, legend.position = c(0.6, 0.1))
```
</div>

相似地，**Wilcoxon 配对组**和**Wilcoxon 符号秩**的唯一差别，就是它是对配对的 $y-x$ 差的符号秩进行检验。

$signed\_rank(y_2-y_1) = \beta_0 \qquad \mathcal{H}_0: \beta_0 = 0$


### R 代码：配对样本 t 检验

```{r, results='hold'}
a <- t.test(y, y2, paired = TRUE) # Built-in paired t-test
b <- lm(y - y2 ~ 1) # Equivalent linear model
```

结果：

```{r, echo=FALSE}
df <- data.frame(
  model = c("t.test", "lm"),
  mean = c(a$estimate, b$coefficients),
  p.value = c(a$p.value, tidy(b)$p.value),
  df = c(a$parameter, b$df.residual),
  t = c(a$statistic, tidy(b)$statistic),
  conf.low = c(a$conf.int[1], confint(b)[1]),
  conf.high = c(a$conf.int[2], confint(b)[2])
)

print_df(df)
```

<div class="fold o">
```{r, echo=FALSE, results='hold'}
a
summary(b)
```
</div>


### R 代码：Wilcoxon 配对组检验

我们再一次运用符号秩转换技巧。这依然是近似值，但是非常接近：

```{r, results='hold'}
# Built-in Wilcoxon matched pairs
a <- wilcox.test(y, y2, paired = TRUE)

# Equivalent linear model:
b <- lm(signed_rank(y - y2) ~ 1)

# Bonus: identical to one-sample t-test ong signed ranks
c <- t.test(signed_rank(y - y2))
```

结果：

```{r, echo=FALSE}
# Print nicely
df <- data.frame(
  model = c("wilcox.test", "lm", "t.test"),
  p.value = c(a$p.value, tidy(b)$p.value, c$p.value),
  mean_rank_diff = c(NA, b$coefficients, c$estimate)
)

print_df(df)
```

<div class="fold o">
```{r, echo=FALSE, results='hold'}
a
summary(b)
c
```
</div>

对于大样本量（N >> 100），这计算方式某种程度上比较接近**符号检验**。但是本例子中这种近似效果较差。

# 双均值

## 独立 t 检验和 Mann-Whitney U 检验 {#t2}
### 理论：作为线性模型

独立 t 检验模型：两个均值来预测 $y$。

$y_i = \beta_0 + \beta_1 x_i \qquad \mathcal{H}_0: \beta_1 = 0$

上式中，$x_i$ 是示性变量（0 或 1），用于示意数据点 $i$ 是从一个组里采样还是另一个组里采样的。[示性变量（indicator variable 或 dummy coding）](https://en.wikipedia.org/wiki/Dummy_variable_(statistics)) 存在于很多线性模型当中，我们很快就会看到它有什么用途。

**Mann-Whitney U 检验**（也被称为对两个独立组的 **Wilcoxon 秩和检验**；这次没有*符号*秩了）是有着非常接近的近似的相同模型，除了它不是在原有值而是在 $x$ 和 $y$ 的秩上计算的：

$rank(y_i) = \beta_0 + \beta_1 x_i \qquad \mathcal{H}_0: \beta_1 = 0$

对我来说，这种等价性使得“非参”统计量更为容易地理解了。这种近似[在每个组样本量大于 11 的时候比较合适，在每个组样本量大于 30 的时候视觉效果上相当完美](simulations/simulate_mannwhitney.html).

### 理论：示性变量 {#dummy}

示性变量可以用图像辅助理解。这个变量在 x 轴，所以第一个组的数据点位于 $x = 0$，第二个组的位于 $x = 1$。然后 $\beta_0$ 是截距（蓝线），$\beta_1$ 是两个均值之间的斜率（红线）。为什么？因为当 $\Delta x = 1$ 的时候，斜率等于相差值：

$slope = \Delta y / \Delta x = \Delta y / 1 = \Delta y = difference$

奇迹啊！即使类别之间的差值也可以用线性模型来表达！这真的是一把瑞士军刀。

<div class="fold s">
```{r}
# Data
N <- 20 # Number of data points per group
D_t2 <- data.frame(
  x = rep(c(0, 1), each = N),
  y = c(rnorm_fixed(N, 0.3, 0.3), rnorm_fixed(N, 1.3, 0.3))
)

# Plot
P_t2 <- ggplot(D_t2, aes(x = x, y = y)) +
  stat_summary(
    fun.y = mean, geom = "errorbar",
    aes(ymax = ..y.., ymin = ..y.., color = "something"), lwd = 2
  ) +
  geom_segment(x = -10, xend = 10, y = 0.3, yend = 0.3, lwd = 2, aes(color = "beta_0")) +
  geom_segment(x = 0, xend = 1, y = 0.3, yend = 1.3, lwd = 2, aes(color = "beta_1")) +
  scale_color_manual(
    name = NULL, values = c("blue", "red", "darkblue"),
    labels = c(
      bquote(beta[0] * " (group 1 mean)"),
      bquote(beta[1] * " (slope = difference)"),
      bquote(beta[0] + beta[1] %.% 1 * " (group 2 mean)")
    )
  )
# scale_x_discrete(breaks=c(0.5, 1.5), labels=c('1', '2'))

theme_axis(P_t2, jitter = TRUE, xlim = c(-0.3, 2), legend.position = c(0.53, 0.08))
```
</div>


### 理论：示性变量（后续） {#dummy2}

如果你觉得你理解了示性变量了，可以直接跳到下一章节。这里是对示性变量更为详细的解释：

如果数据点采样自第一个组，即，$x_i = 0$，模型就会变成 $y = \beta_0 + \beta_1 \cdot 0 = \beta_0$。换句话说，模型预测数据的值是 $beta_0$。这意味着作为一堆数据点的最好的预测，$\beta$ 是这些数据点的*均值*，所以 $\beta_0$ 是第 1 组的均值。

另一方面，采样自第二个组的数据点有 $x_i = 1$，所以模型变成了 $y_i = \beta_0 + \beta_1\cdot 1 = \beta_0 + \beta_1$。换句话说，我们加上了 $\beta_1$，从第一组的均值移动到了第二组的均值。所以 $\beta_1$ 成为了两个组的*均值之差*。

举个例子，假设第 1 组人是 25 岁（$\beta_0 = 25$），第 2 组人 28 岁（$\beta_1 = 3$），那么对于第 1 组的人的模型是 $y = 25 + 3 \cdot 0 = 25$，第 2 组的人的模型是 $y = 25 + 3 \cdot 1 = 28$。

呼，搞定！对于新来者，理解示性变量需要一些时间，但是你只需要懂得加法和乘法就能上手了！

### R 代码：独立 t 检验

提醒一下，当我们在 R 里写 `y ~ 1 + x`，它是 $y = \beta_0 \cdot 1 + \beta_1 \cdot x$ 的简写，R 会为你计算 $\beta$ 值。因此，`y ~ 1 + x` 是 R 里面表达 $y = a \cdot x + b$ 的形式。

注意相等的 `t`、`df`、`p`和估计值。我们可以用 `confint(lm(...))` 获得置信区间。

```{r, results='hold'}
# Built-in independent t-test on wide data
a <- t.test(y, y2, var.equal = TRUE)

# Be explicit about the underlying linear model by hand-dummy-coding:
group_y2 <- ifelse(group == "y2", 1, 0) # 1 if group == y2, 0 otherwise
b <- lm(value ~ 1 + group_y2) # Using our hand-made dummy regressor

# Note: We could also do the dummy-coding in the model
# specification itself. Same result.
c <- lm(value ~ 1 + I(group == "y2"))
```

结果：

```{r, echo=FALSE}
# Put it together. Note that the signs are inversed for t.test.
df <- data.frame(
  model = c("t.test", "lm"),
  mean_y = c(at$estimate1, bt$estimate[1]),
  difference = c(at$estimate2 - at$estimate1, bt$estimate[2]),
  p.value = c(at$p.value, bt$p.value[2]),
  df = c(at$parameter, b$df.residual),

  conf.low = c(-at$conf.high, confint(b)[2, 1]),
  conf.high = c(-at$conf.low, confint(b)[2, 2])
)

# Print it nicely
print_df(df)
```

<div class='fold o'>
```{r, echo=FALSE, results='hold'}
a
summary(b)
summary(c)
```
</div>



### R 代码：Mann-Whitney U 检验

```{r, results='hold'}
# Wilcoxon / Mann-Whitney U
a <- wilcox.test(y, y2)

# As linear model with our dummy-coded group_y2:
b <- lm(rank(value) ~ 1 + group_y2) # compare to linear model above
```


```{r, echo=FALSE}
df <- data.frame(
  model = c("wilcox.test", "lm"),
  p.value = c(a$p.value, tidy(b)$p.value[2]),
  rank_diff = c(NA, b$coefficients[2])
)
print_df(df)
```

<div class='fold o'>
```{r, echo=FALSE, results='hold'}
a
summary(b)
```
</div>



## Welch t 检验 {#welch}

这等价于以上（学生）[独立 t 检验](#t2)，除了学生 t 检验假设同方差，而 **Welch t 检验** 没有这个假设。所以线性模型是相同的，区别在于，我们对每一个组指定一个方差。我们可用 `nlme` 包（[查阅细节](https://stats.stackexchange.com/questions/142685/)）：

```{r, results='hold'}
# Built-in
a <- t.test(y, y2, var.equal = FALSE)

# As linear model with per-group variances
b <- nlme::gls(value ~ 1 + group_y2, method = "ML", 
               weights = nlme::varIdent(form = ~ 1 | group))
```

结果：

```{r, echo=FALSE}
df <- data.frame(
  model = c("t.test", "gls"),
  mean_y = c(a$estimate[1], b$coefficients[1]),
  mean_diff = c(a$estimate[2] - a$estimate[1], b$coefficients[2]),
  p.value = c(a$p.value, coef(summary(b))[2, 4]),
  t = c(a$statistic, -coef(summary(b))[2, 3]),
  conf.low = c(-a$conf.int[2], confint(b)[2, 1]),
  conf.high = c(-a$conf.int[1], confint(b)[2, 2])
)
print_df(df)
```

<div class='fold o'>
```{r, echo=FALSE, results='hold'}
a
summary(b)
```
</div>


# 三个或多个均值

ANOVA 是（只）有类别自变量的线性模型，所以它们可以简单地扩展我们上述的所有模型，并重度依赖示性变量。如果你还没准备好，确保去阅读[示性变量一节](#dummy)。

## 单因素方差分析（one-way ANOVA）和 Kruskal-Wallis 检验 {#anova1}
### 理论：作为线性模型

模型：每组一个均值来预测 $y$。

$y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_3 +... \qquad \mathcal{H}_0: y = \beta_0$

其中 $x_i$ 是示性变量（$x=0$ 或 $x=1$），且最多只有一个 $x_i=1$ 且其余 $x_i=0$。 

注意这和我们已做的其它模型“有很大的相同之处”。如果只有两个组，这个模型就是 $y = \beta_0 + \beta_1*x$，即[独立 t 检验](#t2)。如果只有一个组，这就是 $y = \beta_0$，即[单样本 t 检验](#t1)。从可视化中可以很容易地看出来 ---- 只要遮盖掉一些组然后看看图像是否对上了其它可视化结果。

<div class="fold s">
```{r}
# Figure
N <- 15
D_anova1 <- data.frame(
  y = c(
    rnorm_fixed(N, 0.5, 0.3),
    rnorm_fixed(N, 0, 0.3),
    rnorm_fixed(N, 1, 0.3),
    rnorm_fixed(N, 0.8, 0.3)
  ),
  x = rep(0:3, each = 15)
)
ymeans <- aggregate(y ~ x, D_anova1, mean)$y
P_anova1 <- ggplot(D_anova1, aes(x = x, y = y)) +
  stat_summary(
    fun.y = mean, geom = "errorbar",
    aes(ymax = ..y.., ymin = ..y.., color = "intercepts"), lwd = 2
  ) +
  geom_segment(x = -10, xend = 100, y = 0.5, yend = 0.5, lwd = 2, aes(color = "beta_0")) +
  geom_segment(x = 0, xend = 1, y = ymeans[1], yend = ymeans[2], lwd = 2, aes(color = "betas")) +
  geom_segment(x = 1, xend = 2, y = ymeans[1], yend = ymeans[3], lwd = 2, aes(color = "betas")) +
  geom_segment(x = 2, xend = 3, y = ymeans[1], yend = ymeans[4], lwd = 2, aes(color = "betas")) +
  scale_color_manual(
    name = NULL, values = c("blue", "red", "darkblue"),
    labels = c(
      bquote(beta[0] * " (group 1 mean)"),
      bquote(beta[1] * ", " * beta[2] * ",  etc. (slopes/differences to " * beta[0] * ")"),
      bquote(beta[0] * "+" * beta[1] * ", " * beta[0] * "+" * beta[2] * ", etc. (group 2, 3, ... means)")
    )
  )

theme_axis(P_anova1, xlim = c(-0.5, 4), legend.position = c(0.7, 0.1))
```
</div>

单因素方差分析有一个对数线性版本，称为[拟合优度](#goodness)检验，我们稍后会讲到。顺便一说，因为我们现在对多个 $x$ 进行回归，因此单因素方差分析是 **多元回归** 模型。

**Kruskal-Wallis** 检验只是对于秩转换的 $y$（`value`）的 **单因素方差分析**：

$rank(y) = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_3 +...$

这个近似在 12 或更多数据点时候已经近似得[足够好](simulations/simulate_kruskall.html)。同样，如果你对一个或两个组做这个检验，我们已经有对应等式，分别为 [Wilcoxon 符号秩检验](#t1) 或 [Mann-Whitney U 检验](#t2)。 


### 示例数据

我们创建可能取值为 `a`、`b`、`c` 的类别变量（本文中，“factor”翻译为“类别变量”或“因子”，“level”翻译为“取值范围”或“水平”；就译者认为，这两个词语的前一种翻译更贴近常见汉语，后一种翻译虽然简练但是不知所云。----译者注），那么**单因素方差分析**基本上成为了“三样本 t 检验”。我们手动对每个组创建[示性变量](#dummy)。

```{r}
# Three variables in "long" format
N <- 20 # Number of samples per group
D <- data.frame(
  value = c(rnorm_fixed(N, 0), rnorm_fixed(N, 1), rnorm_fixed(N, 0.5)),
  group = rep(c("a", "b", "c"), each = N),

  # Explicitly add indicator/dummy variables
  # Could also be done using model.matrix(~D$group)
  # group_a = rep(c(1, 0, 0), each=N),  # This is the intercept. No need to code
  group_b = rep(c(0, 1, 0), each = N),
  group_c = rep(c(0, 0, 1), each = N)
) # N of each level
```
```{r, echo=FALSE}
print_df(D, navigate=TRUE)
```

伴随着组别 a 的截距全都展示了出来，我们看到每一行有且仅有另一个组 b 或组 c 的参数添加进去，用于预测 `value`（滑动到表格最后）。因此组 b 的数据点永远不会影响到组 c 的估计值。


### R 代码：单因素方差分析

OK，我们来看看一个专用的**方差分析**函数（`car::Anova`）和手动创建示性变量的 `lm` 线性模型结果是否一致：


```{r, results='hold'}
# Compare built-in and linear model
a <- car::Anova(aov(value ~ group, D)) # Dedicated ANOVA function
b <- lm(value ~ 1 + group_b + group_c, data = D) # As in-your-face linear model
```

结果：

```{r, echo=FALSE}
df <- data.frame(
  model = c("Anova", "lm"),
  df = c(a$Df[1], glance(b)$df - 1), # -1? https://github.com/tidymodels/broom/issues/273
  df.residual = c(a$Df[2], b$df.residual),
  F = c(a$`F value`[1], bt$statistic),
  p.value = c(a$`Pr(>F)`[1], bt$p.value)
)
print_df(df, 5)
```

<div class='fold o'>
```{r, echo=FALSE, results='hold'}
a
summary(b)
```
</div>

实际上，`car::Anova` 和 `aov` 就是 `lm` 包装而来的，所以相等结果一点都不令人感到意外。这只说明了，可直接理解为线性模型的示性变量公式，是缩写语法 `y ~ factor` 背后的模型。实际上，真正的唯一使用 `aov` 和 `car::Anova` 而不使用 `lm` 的原因，是为了得到一个优雅格式化的方差分析表格。


`lm` 的默认输出包含了参数估计结果（额外收获！），你可以将上述 R 代码展开来看。然而，因为它就是方差分析模型，你也可以用 `coefficients(aov(...))` 得到参数估计结果。

注意，我没有使用 `aov` 函数，因为它计算了第一类平方和，这种计算方式很不受鼓励。围绕着使用第二类平方和（`car::Anova` 默认）还是第三类平方和（使用 `car::Anova(..., type=3)`）有着**很多**争论，但是我们这里略过不提。


### R 代码：Kruskal-Wallis 检验

```{r, results='hold'}
a <- kruskal.test(value ~ group, D) # Built-in
b <- lm(rank(value) ~ 1 + group_b + group_c, D) # As linear model
# The same model, using a dedicated ANOVA function. It just wraps lm.
c <- car::Anova(aov(rank(value) ~ group, D)) 
```

结果：

```{r, echo=FALSE}
df = data.frame(
  model = c('kruskal.test', 'lm'),
  df = c(a$parameter, glance(b)$df - 1),  # -1? https://github.com/tidymodels/broom/issues/273
  p.value = c(a$p.value, glance(b)$p.value)
)
print_df(df)
```

<div class='fold o'>
```{r, echo=FALSE, results='hold'}
a
summary(b)
c
```
</div>



## 双因素方差分析（two-way ANOVA）（待绘图） {#anova2}
### 理论：作为线性模型

模型：每组一个均值（主效应）加上这些均值乘以各个因子（交互效应）。尽管在一个更大的模型框架里，实际上主效应就是上述[单因素方差分析](#anova1)模型。即使交互效应只是一些数字乘以另外一些识数字，但是它更难抽象地解释。我会把这些解释内容留给课堂上的老师们，而聚焦在等价表达之上。 :-)

使用矩阵记号：

$y = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \beta_3 X_1 X_2 \qquad \mathcal{H}_0: \beta_3 = 0$

这里 $\beta_i$ 是 beta 的向量，其中之后一个会被示性向量 $X_i$ 所选取。这里出现的$\mathcal{H}_0$ 是交互效应。注意，截距是 $\beta_0$ 是所有因子中第一个水平的均值，而其它所有的 $\beta$ 都是相对于 $\beta_0$ 的值。

继续探究上文单因素方差分析的数据集，我们加上交互因子 `mood`（情绪），从而我们能够测试 `group:mood` 的交互效应（3x2 ANOVA）。同样，为了使用线性模型，我们把这个因子转为[示性变量](#dummy)。

```{r}
# Crossing factor
D$mood <- c("happy", "sad")
# Dummy coding
D$mood_happy <- ifelse(D$mood == "happy", 1, 0) # 1 if mood==happy. 0 otherwise.
# D$mood_sad = ifelse(D$mood == 'sad', 1, 0)  # Same, but we won't be needing this
```

```{r, echo=FALSE}
print_df(D, navigate = TRUE)
```

$\beta_0$ 成为了 a 组的开心者！

<div class="fold s">
```{r}
# Add intercept line
# Add cross...
# Use other data?
means <- lm(value ~ mood * group, D)$coefficients
P_anova2 <- ggplot(D, aes(x = group, y = value, color = mood)) +
  geom_segment(x = -10, xend = 100, y = means[1], yend = 0.5, col = "blue", lwd = 2) +
  stat_summary(fun.y = mean, geom = "errorbar", aes(ymax = ..y.., ymin = ..y..), lwd = 2)
theme_axis(P_anova2, xlim = c(-0.5, 3.5)) + theme(axis.text.x = element_text())
```
</div>


### R 代码：双因素方差分析

现在我们转向 R 里的真实建模。我们对比专用的 ANOVA 函数（`car::Anova`；原因参见[单因素方差分析](#anova1)一节），以及线性模型函数（`lm`）。注意，在单因素方差分析里，我们一次性检验全部因子交互效应，这其中涉及到多个参数（这个例子里有两个参数）。所以我们不能查看总体模型估计结果或者任意一个参数结果。因此，我使用[似然比检验（likelihood-ratio test）](https://en.wikipedia.org/wiki/Likelihood-ratio_test)来比较双因素方差分析模型（“饱和（staturated）模型”）和没有交互效应的模型。`anova` 函数就是这个检验。尽管这看起来在作弊，但是它实际上就只是在我们已经拟合了的模型上计算似然（likelihood）、p 值，等等，所以是没有问题的！

```{r, results='hold'}
# Dedicated two-way ANOVA functions
a <- car::Anova(aov(value ~ mood * group, D), type = "II") # Normal notation. "*" both multiplies and adds main effects
b <- car::Anova(aov(value ~ mood + group + mood:group, D)) # Identical but more verbose about main effects and interaction

# Testing the interaction terms as linear model.
full <- lm(value ~ 1 + group_b + group_c + mood_happy + group_b:mood_happy + group_c:mood_happy, D) # Full model
null <- lm(value ~ 1 + group_b + group_c + mood_happy, D) # Without interaction
c <- anova(null, full) # whoop whoop, same F, p, and Dfs
```

结果：

```{r, echo=FALSE, warning=FALSE}
at <- tidy(a)[3, ]
at$res.df <- tidy(a)[4, ]$df
at$rss <- tidy(a)[4, ]$sumsq
ct <- tidy(c)[2, ]

df <- bind_rows(at, ct) %>%
  mutate(model = c("Anova mood:group", "lm LRT")) %>%
  rename(
    F = statistic,
    res.sumsq = rss
  ) %>%
  select(model, F, df, p.value, sumsq, res.sumsq)
print_df(df)
```

<div class='fold o'>
```{r, echo=FALSE, results='hold'}
a
c
```
</div>

下面展示了近似的主因素模型。更加准确的方差分析主效应的精确计算，需要[更加繁琐的](https://stats.idre.ucla.edu/stata/faq/how-can-i-get-anova-simple-main-effects-with-dummy-coding/)计算步骤，而且还依赖于使用第二型还是第三型平方和来进行推断。

在模型的汇总统计量里可以找到可对比以上 `Anova` 拟合的主因素效应的数值。

```{r, results='hold'}
# Main effect of group.
e <- lm(value ~ 1 + group_b + group_c, D)

# Main effect of mood.
f <- lm(value ~ 1 + mood_happy, D)
```


```{r, echo=FALSE}
et <- glance(e)
et$df <- et$df - 1 # see https://github.com/tidymodels/broom/issues/273
ft <- glance(f)
ft$df <- ft$df - 1 # see https://github.com/tidymodels/broom/issues/273
at <- tidy(a)[1:2, ]

df <- bind_rows(et, ft, at) %>%
  mutate(
    model = c("lm", "lm", "Anova", "Anova"),
    term = c("group", "mood", "mood", "group")
  ) %>%
  rename(F = statistic) %>%
  select(term, model, df, F, p.value) %>%
  arrange(term, model)
print_df(df, 5)
```

<div class='fold o'>
```{r, echo=FALSE, results='hold'}
summary(e)
summary(f)
```
</div>


## 协方差分析（ANCOVA） {#ancova}

协方差分析，只是方差分析加上被回归连续变量，从而模型里包含了连续以及（被转化为示性变量的）类别因变量。比如说，如果我们沿用上文[单因素方差分析](#anova1)的例子，那么我们可以加上 `age`，从而变成**单因素协方差分析（one-way ANCOVA）**：

$y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + ... + \beta_3 age$

其中，$x_i$ 是我们熟悉的示性变量。$\beta_0$ 是第一个组在 $age=0$ 时候的均值。你可以用这个方法，把所有的方差分析转化成为协方差分析，比如说在上一节的**双因素方差分析**加上 $\beta_N \cdot age$。但我们先继续探究单因素协方差分析，从添加 $age$ 到模型里开始：

```{r, results='hold'}
# Update data with a continuous covariate
D$age <- D$value + rnorm_fixed(nrow(D), sd = 3) # Correlated to value
```

比起使用位于 x 轴的位置，最好使用颜色来可视化各组数据。$\beta$ 依然是数据的平均 $y$ 移动量，唯一的不同是我们现在用斜率而不是截距来对每一组进行建模。换句话说，单因素方差分析实际上是对于每一组（$y = \beta_0$）的[单样本 t 检验](#t1)，而**单因素协方差分析**实际上是每一组（$y_i = \beta_0 + \beta_i + \beta_1 \cdot age$）的[Pearson 相关性检验](#correlation)：


<div class="fold s">
```{r}
# For linear model plot
D$pred <- predict(lm(value ~ age + group, D))

# Plot
P_ancova <- ggplot(D, aes(x = age, y = value, color = group, shape = group)) +
  geom_line(aes(y = pred), lwd = 2)

# Theme it
theme_axis(P_ancova, xlim = NULL, ylim = NULL, legend.position = c(0.8, 0.2)) + 
  theme(axis.title = element_text())
```
</div>

这里是使用线性模型运行单因素方差分析的 R 代码：

```{r, results='hold'}
# Dedicated ANCOVA functions. The order of factors matter in pure-aov (type-I variance).
# Use type-II (default for car::Anova) or type-III (set type=3),
a <- car::Anova(aov(value ~ group + age, D))
# a = aov(value ~ group + age, D)  # Predictor order matters. Not nice!

# As dummy-coded linear model.
full <- lm(value ~ 1 + group_b + group_c + age, D)

# Testing main effect of age using Likelihood-ratio test
null_age <- lm(value ~ 1 + group_b + group_c, D) # Full without age. One-way ANOVA!
result_age <- anova(null_age, full)

# Testing main effect of groupusing Likelihood-ratio test
null_group <- lm(value ~ 1 + age, D) # Full without group. Pearson correlation!
result_group <- anova(null_group, full)
```


结果：

```{r, echo=FALSE}
at <- tidy(a)[1:2, ]
at$rss <- a$`Sum Sq`[3]
at$res.df <- a$Df[3]
groupt <- tidy(result_group)[2, ]
aget <- tidy(result_age)[2, ]

df <- bind_rows(at, groupt, aget) %>%
  mutate(
    model = rep(c("Anova", "lm"), each = 2),
    term = c("group", "age", "group", "age")
  ) %>%
  rename(
    F = statistic,
    res.sumsq = rss
  ) %>%
  select(term, model, F, df, p.value, sumsq, everything()) %>%
  arrange(term)
print_df(df)
```

<div class='fold o'>
```{r, echo=FALSE, results='hold'}
a
result_age
result_group
```
</div>

<!--
Is there a well-known "non-parametric" ANCOVA? No, but now that we understand it as a mix of a **Pearson correlation** and **t-tests**, you can get creative and make one up. If we rank the $y$ and the $x$ we get a **Spearman correlation** ($rank(y) ~ \beta_0 + rank(x)$) and at the same time the **Wilcoxon** ($rank(y) ~ 1):

$rank(y) = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + ... + \beta_3 rank(age)$

As I noted earlier, this does not match up perfectly with the true "non-parametric" model (if that exists), but it can be very close!

```{r}
full <- lm(rank(value) ~ group + rank(age), D)
null <- lm(rank(value) ~ rank(age), D)
anova(null, full)
sm::sm.ancova(x = D$age, y = D$value, group = D$group, display = "none", model = "equal")
```
-->


# 比率（proportion）：卡方（chi-square）检验是对数线性模型

回想一下，当你使用了对数转换的时候，你就可以简单地处理*比率（proportion）*，举例来说，$x$ 每一个单位的增加，都会带来 $y$ 的一定数量的百分比的增加。这种性质使它成为了最简单（因此是最好的！）方式之一去清晰地理解计数数据和列联表。查阅[此简介文章](https://www.uni-tuebingen.de/fileadmin/Uni_Tuebingen/SFB/SFB_833/A_Bereich/A1/Christoph_Scheepers_-_Statistikworkshop.pdf)看看如何使用线性模型来理解卡方检验。


## 拟合优度（goodness of fit）检验 {#goodness}
理论：作为对数线性模型

模型：单独一个截距来预测 $log(y)$。

我提议你参考阅读[列联表一节](#contingency)，基本上它就是“双因素拟合优度检验”。

<!--
Before log-transforming, this is a one-way ANOVA:

$y = \beta_1*x_1 + \beta_2*x_2 + \beta_3*x_3 +... \qquad \mathcal{H}_0: y = \beta_1$

We should think of these as proportions of $sum(y)$ for reasons that will be clearer in [the section on contingency tables](#contingency):

$y = N\beta_1*x_1/N + N\beta_2*x_2/N + N\beta_3*x_3/N + ...$

But we fit parameters on the log_transformed model (ignoring the proportion-notation for now):

$log(y) = log(\beta_1*x_1 + \beta_2*x_2 + \beta_3*x_3 +...) \qquad \mathcal{H}_0: log(y) = log(\beta_1)$

$log(y) = log(N\beta_1*x_1/N + N)$
-->

### 示例数据

本例子中，我们需要一些“宽”的计数数据：

```{r}
# Data in long format
D <- data.frame(
  mood = c("happy", "sad", "meh"),
  counts = c(60, 90, 70)
)
# Dummy coding for the linear model
D$mood_happy <- ifelse(D$mood == "happy", 1, 0)
D$mood_sad <- ifelse(D$mood == "sad", 1, 0)
```

```{r, echo=FALSE}
print_df(D)
```


### R 代码：拟合优度检验

现在，让我们展示一下，拟合优度检验实际上就是单因素方差分析的对数线性转换版本。我们设置 `family = poisson()`，这个设置默认使用 log 作为[联连函数（link function）](https://en.wikipedia.org/wiki/Generalized_linear_model#Link_function)（`family = poisson(link='log')`）。

```{r, results='hold'}
# Built-in test
a <- chisq.test(D$counts)

# As log-linear model, comparing to an intercept-only model
full <- glm(counts ~ 1 + mood_happy + mood_sad, data = D, family = poisson())
null <- glm(counts ~ 1, data = D, family = poisson())
b <- anova(null, full, test = "Rao")

# Note: glm can also do the dummy coding for you:
c <- glm(counts ~ mood, data = D, family = poisson())
```

我们来看看结果：

```{r, echo=FALSE, warning=FALSE, message=FALSE}
df <- data.frame(
  model = c("chisq.test", "glm LRT"),
  Chisq = c(a$statistic, b$Rao[2]),
  df = c(a$parameter, b$Df[2]),
  p.value = c(a$p.value, b$`Pr(>Chi)`[2])
)
print_df(df)
```

<div class='fold o'>
```{r, echo=FALSE, results='hold'}
a
b
```
</div>


注意，这里奇怪的 `anova(..., test='Rao')`，实际上只是说 p 值需要使用（Rao）[score 检验（又被称为“拉格朗日乘子检验（Lagrange multiplier test，LM test）”）](https://en.wikipedia.org/wiki/Score_test)。我们也可以使用 `test='Chisq'` 或 `test='LRT'`，它们会返回近似的 p 值。你可能认为我们这里作弊了，偷偷地对卡方模型进行后续处理。然而，`anova` 仅仅指定了 p 值的计算方式，而内部的所有对数线性模型都发生在 `glm` 其中。

顺带一说，如果只有两个计数变量，而且样本量较大（N > 100），这个模型开始有效地近似于**二项检验（binomial test）** `binom.test`。但是这个样本量比通常情况要更大，所以我没有认为这是经验准则，也不会在此进一步探索。


## 列联表 {#contingency}
理论：作为对数线性模型

这里的理论会变得更令人费解，我会简单地写一下，从而你可以*感受*到它其实就是对数线性[双因素方差分析模型](#anova2)。来，开始探索......

对于双因素列联表，计数变量 $y$ 的模型使用了列联表的边缘比率来建模。为什么这是可行的呢？答案比较高深，我们不会在这里详解，但读者可以通过查阅 [Christoph Scheepers 的相关幻灯片](https://www.uni-tuebingen.de/fileadmin/Uni_Tuebingen/SFB/SFB_833/A_Bereich/A1/Christoph_Scheepers_-_Statistikworkshop.pdf)来获得精彩的解答。这个模型包含了很多计数变量和回归系数 $A_i$ 和 $B_i$：

$$y_i = N \cdot x_i(A_i/N) \cdot z_j(B_j/N) \cdot x_{ij}/((A_i x_i)/(B_j z_j)/N)$$ 

多复杂呀！！！这里，$i$ 是行标号，$j$ 列标号，$x_{something}$ 是那一行和/或列的求和值：$N = sum(y)$。请记得，$y$ 是计数变量，所以 $N$ 其实就是总计数值。

我们可以通过定义*比率* 来简化以上记号：$\alpha_i = x_i(A_i/N)$，$\beta_i = x_j(B_i/N)$，$\alpha_i\beta_j =  x_{ij}/(A_i x_i)/(B_j z_j)/N$。重写模型如下：

$$y_i = N \cdot \alpha_i \cdot \beta_j \cdot \alpha_i\beta_j$$

嗯，好多了。然而，这里依然有很多乘法项，使得我们很难直觉上理解变量之间是如何交互的。如果我们记得 $\log(A \cdot B) = \log(A) + \log(B)$，那么我们可以使得变得更为清晰易懂。两边取对数变换，可得：

$$\log(y_i) = \log(N) + \log(\alpha_i) + \log(\beta_j) + \log(\alpha_i\beta_j)$$

太爽了！现在我们可以直观地理解，回归系数（都是比率）是怎样独立地影响到 $y$ 的。这就是为什么对数变换对比率数据如此有效。注意到，这其实就是[双因素方差分析模型](#anova2)加上一些对数变换，从而我们可以回到我们所熟悉的旧线性模型----除了对系数的解释发生了变化而已！此外我们不能继续使用 R 里的 `lm` 函数了。


### 示例数据

我们需要一些“长”数据，并且需要保存为表格格式，才能作为 `chisq.test` 的输入：

```{r}
# Contingency data in long format for linear model
D <- data.frame(
  mood = c("happy", "happy", "meh", "meh", "sad", "sad"),
  sex = c("male", "female", "male", "female", "male", "female"),
  Freq = c(100, 70, 30, 32, 110, 120)
)

# ... and as table for chisq.test
D_table <- D %>%
  spread(key = mood, value = Freq) %>% # Mood to columns
  select(-sex) %>% # Remove sex column
  as.matrix()

# Dummy coding of D for linear model (skipping mood=="sad" and gender=="female")
# We could also use model.matrix(D$Freq~D$mood*D$sex)
D$mood_happy <- ifelse(D$mood == "happy", 1, 0)
D$mood_meh <- ifelse(D$mood == "meh", 1, 0)
D$sex_male <- ifelse(D$sex == "male", 1, 0)
```

```{r, echo=FALSE}
print_df(D)
```


### R 代码：卡方检验

接下来我们看看卡方检验模型和对数线性模型之间的等价性。这个过程和上述[双因素方差分析](#anova2)过程非常相似：

```{r, results='hold'}
# Built-in chi-square. It requires matrix format.
a <- chisq.test(D_table)

# Using glm to do a log-linear model, we get identical results when testing the interaction term:
full <- glm(Freq ~ 1 + mood_happy + mood_meh + sex_male + 
              mood_happy * sex_male + mood_meh * sex_male, data = D, family = poisson())
null <- glm(Freq ~ 1 + mood_happy + mood_meh + sex_male, data = D, family = poisson())
b <- anova(null, full, test = "Rao") # Could also use test='LRT' or test='Chisq'

# Note: let glm do the dummy coding for you
full <- glm(Freq ~ mood * sex, family = poisson(), data = D)
c <- anova(full, test = "Rao")

# Note: even simpler syntax using MASS:loglm ("log-linear model")
d <- MASS::loglm(Freq ~ mood + sex, D)
```


```{r, echo=FALSE, warning=FALSE}
df <- data.frame(
  model = c("chisq.test", "glm", "loglm"),
  Chisq = c(a$statistic, b$Rao[2], d$pearson),
  df = c(a$parameter, b$Df[2], d$df),
  p.value = c(a$p.value, b$`Pr(>Chi)`[2], summary(d)$tests[2, 3])
)
print_df(df)
```

<div class='fold o'>
```{r, echo=FALSE, results='hold'}
a
b
c
d

summary(full)
```
</div>

我代码里用了 `summary(full)`，从而你可以取消以上代码的折叠，查看回归模型拟合的系数的原始值。作为对数线性模型，这些系数表示了：如果跳转到一个类别的话，$y$ 将会获得多少*比例上的提升*。

# 资料来源和更多的等价性模型 {#links}

下面提供了对其它介绍了一部分本文内容的资料来源的链接，它们也包含了更多这里没有提到的等价性模型：

 * Cross Validated 网站上，[我的原始想法](https://stats.stackexchange.com/questions/303269/common-statistical-tests-as-linear-models)。 
 * 对于“非参”检验，[我之前提出的疑问](https://stats.stackexchange.com/questions/210529/are-parametric-tests-on-rank-transformed-data-equivalent-to-non-parametric-test?noredirect=1#comment399981_210529)，和有用的答案。
 * StackOverflow 网站上，这个关于 t 检验和方差分析的[问题和回答](https://stats.stackexchange.com/questions/59047/how-are-regression-the-t-test-and-the-anova-all-versions-of-the-general-linear)。
 * [Christoph Scheepers 的幻灯片](https://www.uni-tuebingen.de/fileadmin/Uni_Tuebingen/SFB/SFB_833/A_Bereich/A1/Christoph_Scheepers_-_Statistikworkshop.pdf)，介绍了卡方检验如何被理解为对数线性模型。
 * [Philip M. Alday 的笔记](https://rpubs.com/palday/glm-test)，里面包括了卡方、二项、多项、泊松分布作为对数线性模型和 logistic 模型的理解。这里介绍的“等价性”没有我在本文里所上展示的那些那么精确，因此我没有在本文详细介绍。然而，它们还是对理解这些检验有着优秀的帮助的！
 * [Kristoffer Magnusson 的文章](https://rpsychologist.com/r-guide-longitudinal-lme-lmer)，使用 `lme4::lmer` 混合模型（mixed model）介绍了 RM-ANOVA 和增长模型（growth model）。
 * [Thom Baguley 的文章](https://seriousstats.wordpress.com/2012/02/14/friedman/)，介绍了 Friedman 检验。这篇文章实际上启发了我开始思考“非参”检验的线性模型等价形式，而且最终推动我写下了本文章。

# 教材和课程大纲 {#course}

大部分高等统计书籍（和一些入门书籍）也都同意“所有模型都是 GLMM”。然而，“线性模型”部分通常都是概念上提了一下，而没有清晰的指出细节。我想通过简练的方式，把线性模型当作*工具*。幸运地，大部分对初学者友好的教材后来都合并了：

 * Russ Poldrack 的开源书籍 "Statistical Thinking for the 21st century"（从[关于建模的第 5 章](http://statsthinking21.org/fitting-models-to-data.html)开始）
 * [Jeff Rouder 的课程笔记](https://jeffrouder.blogspot.com/2019/03/teaching-undergrad-stats-without-p-f-or.html)，介绍了仅使用 $R^2$ 和 BIC 来对比模型。它避开了所有关于 p 值、F 值等等的繁琐问题。完整的材料和幻灯片可[在这里找到](https://drive.google.com/drive/folders/1CiJK--bAuO0F-ug3B5I3FvmsCdpPGZ03)。

我说一下对我所做的事情的看法。我已使用了本文的一部分进行教学，并获得了巨大的成功，但是这并不是完整的教学过程，因为我依然没有被分派到教导整一个课程。

我会花费 50% 的时间在数据的线性模型上，因为它包含了学生所需知道的 70%（以下的第 1 点）。剩下来的课程则是关于当你有一个组、两个组等等的数据时候会发生什么事情的。

注意，主流的统计课程的开始部分，一般都是关于对采样和假设检验的理解的；但是我这里把这部分移动到后面，从而学生可以基于之前学习的知识来进行理解，而不是一上来就面对各种陌生的概念。

1. **回归的基础知识**

    1. 回想高中的知识：$y = a \cdot x + b$，然后获得对斜率和截距的非常好的直觉。理解到这条式子能用所有的变量名称来重写：如 `money = profit * time + starting_money`，或 $y = \beta_1x + \beta_2*1$，或去除系数之后可写成 `y ~ x + 1`。如果听众接受程度高的话，可以探索这些模型是如何解[微分方程](https://magesblog.com/post/modelling-change)的，并指出 $y$ 是如何随着 $x$ 的变化*而变化*的。
   
    2. 扩展到多元回归模型。记得这时候要带有非常多的生活例子和练习，从而使这些概念变得直觉上非常容易理解。让听众感叹于这些这么简洁的模型都可以用来描述非常大的数据集。

    3. 介绍对于非数值型数据如何进行秩转换，并进行各种尝试。
   
    4. 教导三种前提假设：数据点的独立性，残差的正态分布性质，和同方差性（homoscedasticity）。
    
    5. 参数的置信（confidence）/可信（credible）区间。指出最大似然估计（Maximum-Likelihood estimate）很难计算，因此区间更为重要。
    
    6. 对以上简单的回归模型，简要地介绍 $R^2$。顺便提及一下，这就是 [Pearson 和 Spearman 相关系数](#correlation)。 

 
2. **特殊情况 #1：一个或两个均值（t 检验、Wilcoxon 检验、Mann-Whitney 检验）：**

    1. **单均值：**当只有一个 x 值得时候，回归模型简化成了 $y = b$。如果 $y$ 不是数值型的，你可以进行秩转换。应用模型假设（只有一个 $x$，因此方差齐性不适用于这里）。顺便提及一下这些仅有截距的模型也分别可称为[单样本 t 检验和 Wilcoxon 符号秩检验](#t1)。
    
    2. **双均值：**如果我们把两个变量一起放在 x 轴，两者均值之差就是斜率。很好！这就能用我们称为线性模型的瑞士军刀来解决。应用模型的假设条件，检查两个组的方差是否相等，相等即方差齐性。这模型称为[独立 t 检验](#t2)。构造一些例子，做一些练习，也许也能加上 Welch 检验，然后加上秩转换 ---- 被称为 Mann-Whitney U 检验 ---- 的版本。
    
    3. *配对样本：*违反了独立性假设。通过计算配对组的差值，这转化成了 2.1（单截距）的等价形式，尽管这种情况有另外的名称：[配对 t 检验和 Wilcoxon 配对组检验](#tpair)。
    
3. **特殊情况 #2：三个或多个均值（方差分析（ANOVA））**

    1. *对类别转化后的[示性变量](#dummy)：*类别的每一个取值范围对应的回归系数，是如何通过乘以一个二元（binary）示性变量，来对每个取值范围对应的截距来进行建模的。（How one regression coefficient for each level of a factor models an intercept for each level when multiplied by a binary indicator.）这只是我们为了使数据能用线性模型建模，而扩展了在 2.1 所做的事情而已。
    
    2. *一个变量的均值：*[单因素方差分析（one-way ANOVA）](#anova1).
    
    3. *两个变量的均值：*[双因素方差分析（two-way ANOVA）](#anova2).
    
    
4. **特殊情况 #3：三个或多个比率（卡方检验）**

    1. *对数变换：*通过对数变换，把“多元乘法”模型转换成线性模型，从而可以对比率进行建模。关于对数线性模型和对比率的卡方检验的等价性，可以查阅[这个非常优秀的介绍](https://www.uni-tuebingen.de/fileadmin/Uni_Tuebingen/SFB/SFB_833/A_Bereich/A1/Christoph_Scheepers_-_Statistikworkshop.pdf)。此外，还需要介绍 (log-) odds ratio（一般被翻译为“比值比”或“优势比”）。当“多元乘法”模型使用对数变换转化为“加法”模型之后，我们仅加上来自 3.1 的示性变量技巧，就会在接下来发现模型等价于 3.2 和 3.3 的方差分析----除了系数的解释发生了变化。
    
    2. *单变量的比率：*[拟合优度检验](#goodness).
    
    3. *双变量的比率：*[列联表](#contingency).


5. **假设检验：** 

    1. *视为模型比较的假设检验：*假设检验，用于对全模型和另一个某参数固定了的（通常为 0，也即从模型中去除）的模型进行比较，而不是对模型进行估计。比如说，在 [t 检验](#t2)把两个均值之一固定为零之后，我们探究单独一个均值（[单样本 t 检验](#t1)）对两个组的所有数据的解释程度如何。如果解释程度比较好，那么我们更倾向于这个单均值模型，而不是双均值模型，因为前者更为简单。所以假设检验其实只是通过比较多个线性模型，来获得比我们在以上 1 至 4 点的真正的量化陈述的更多的量化描述。对于单个参数的检验，假设检验包含的信息更少。但是，对于同一时间的多个参数（如方差分析的类别变量）进行检验的话，模型比较就会变得没有价值了。
    
    2. *似然比：*似然比是一把瑞士军刀，它适用于单样本 t 检验到 GLMM 等情况的建模。BIC 对模型复杂度进行惩罚。还有，加上先验（prior）的话，你就能得到贝叶斯因子（Bayes Factor）。一个工具，就能解决所有问题。我在上文方差分析中使用了似然比检验。


# 不足之处

一些需要澄清的简化前提：

1. 我没在这里覆盖到前提假设的内容。这会在另一篇文章揭晓！但是所有检验都很可能有三个预定假设：a) 数据点的独立性，b) 残差的正态分布性质，c) 同方差性（homoscedasticity）。

2. 我假定所有的零假设是缺失了效应的情况，但是所有原理都和非 0 的零假设所一致的。

3. 我没有讨论推断内容。因为大家都会关心 p 值，因此我在比较中只提到了 p 值，从而简短地展示了背后的模型的等价性。参数的估计值也会展示出相同的等价性。如何进行*推断*则是另一个话题了。我个人是贝叶斯学派的，但是展示贝叶斯学派内容的话，会减少这篇文章的受众。此外，建造[稳健模型](https://en.wikipedia.org/wiki/Robust_statistics)是更好的选择，但是它无法揭示模型的等价性。

4. 本文列表依然缺失了很多其它有名称的检验，有可能在以后添加进来。比如说符号检验（sign test）（要求很大的 N 从而可以有效地使用线性模型来近似），Friedman 检验 -- 即在 `rank(y)` 上的 RM-ANOVA，McNemar 检验，和二项（Binomial）/多项（Multinomial）检验。在[链接一节](#links)可查阅更多的等价模型。如果你认为它们需要在本文提及到，欢迎在本文档的 [github repo](https://github.com/lindeloev/tests-as-linear/) 提交对应说明！


<!--
# Visualization of models (in progress)
These will eventually be included under the respective headers and in the infographic.
```{r echo=FALSE, eval=FALSE, fig.height=1.5, fig.width=2}

# Plot style for icons in table
theme_icon = function(P, jitter=FALSE, xlim=c(-0.5, 2), ylim=c(-0.5, 2)) {
  P = P + theme_bw(15) + 
  coord_cartesian(xlim=xlim, ylim=ylim) +
  theme(axis.title = element_blank(), 
        axis.text = element_blank(),
        axis.ticks = element_blank(),
        title = element_blank(),
        text = element_blank(),
        panel.border = element_blank(),
        panel.grid = element_blank(),
        legend.position = 'none',
        legend.key=element_blank())
  
    # Return jittered or non-jittered plot?
  if(jitter) {
    P + geom_jitter(width=0.1, size=2)
  }
  else {
    P + geom_point(size=2)
  }
}

P_t1_icon = ggplot(D_t1, aes(y=y, x=0)) + 
  stat_summary(fun.y=mean, geom = "errorbar", color='blue', aes(ymax = ..y.., ymin = ..y..), lwd=2)

theme_icon(P_t1_icon, jitter=TRUE)

theme_icon(P_pearson)
#theme_icon(P_t1)
theme_icon(P_tpaired)
theme_icon(P_t2, jitter=TRUE)
theme_icon(P_anova1, xlim=c(-0.5, 4), jitter=TRUE)
theme_icon(P_ancova, xlim=NULL, ylim=NULL)

```
-->
