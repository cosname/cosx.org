---
title: 医学统计学的渊源
date: '2013-08-23T19:22:30+00:00'
author: 冯国双
categories:
  - 生物与医学统计
tags:
  - 医学统计学
  - 变异
  - 抽样
  - 抽样误差
  - 误差
slug: biostats-series1-origin
forum_id: 418959
---

医学统计学应该从什么地方开始讲起呢？多数授课老师的讲课方式是简要说一些医学统计学的概念，然后接着介绍医学统计学的内容、各种概念等。当然，这也是绝大多数教材的结构安排。

我们这里不是讲课，所以我不从这里讲，我们要像讲故事一样。你怎么才能tell story，让别人明白呢？我想首先要讲清楚这个故事的渊源，也就是来龙去脉。那么统计学的渊源是什么呢？所有统计学的发展，或者说统计学之所以存在，只有一个原因，那就是变异以及变异所导致的抽样误差。没有变异，没有抽样误差，就没有统计学存在的理由。想象一下，如果全世界所有人的身高都是1.70米，那还有必要进行抽样做统计推断吗？只要随便量一个人的身高，就知道了全世界人的身高。那统计学还有存在的必要吗？<!--more-->
 
Thanks god和女娲在在创造人类的时候没有让所有人都完全一样，所以才会有今天统计学这门学科，所以才会有今天我能够写这个小文章，所有统计学专业人员才能以此为生。

所以说，变异和抽样误差是统计学的渊源，我们一定要先搞清楚这一点，然后才能开始学习统计学。

那么到底什么是变异呢？变异（variation）也就是不同，通俗来说也就是不一样，可能有的人觉得“不一样”这个字眼太俗气，所以起了个文雅的词叫“变异”。我们的身高都不一样，这就是变异；我们的血压不一样，这也是变异；我们吃了同一种感冒药，我1天就好了，你7天才好，这也是变异。总之，世界上没有完全相同的两片叶子，更不用说两个人，即使双胞胎，也不是完全一样的。所以变异是到处存在的。

可能有人说了，既然每个人都不一样，那还研究什么？尽管变异存在，但我们依然能够在变异之中找到一定的规律，这也正是统计学的目的和作用。比如，尽管我们体质都不一样，但不管怎么样，服了药之后可能都治好了某种疾病；而没有服药的人可能大多数人都没有治好，这就是规律。或者说，尽管每个人体格有异，但多数吸烟的人肺都有一定问题，这也是规律。所以我们要在小变异中发现大规律，这也是统计学存在的目的。

既然统计学是要阐明某种规律，那就要证明这种规律是放之五湖四海皆准的规律，只在一小部分人中存在的规律不一定是真的规律，有可能是偶然。就像某些“大师”声称自己治好了多少例疑难杂症，然后说自己的疗法包治百病。结果一查，一共只治好了3例。只在这3例中有效，这不是规律，这是“瞎猫撞上死老鼠”，这是偶然。

那怎么证明这种规律是真正的规律呢？起码有一点，那就是一定要在大量人群中都存在这种规律，最好是全世界人都有这种规律。然而这听起来就难以实现，怎么可能把全世界人都调查一遍呢，即使是一个县都很难全部调查。所以统计学家就想了一个办法，调查部分人群，然后用统计学的方法根据这部分人的结果来推广到全县、全国、甚至全世界。这就是抽样调查。

我们已经说了，每个人都是不一样的，比如全县有30万人，我只调查了1万人，这1万人肯定跟其余的29万是不一样的，那我怎么就能说明这1万人的结果能推广到30万人呢？这就需要一定的抽样和调查技巧，所以统计学发展出了很多抽样方法，如随机抽样。通过这些好的抽样方法，可以尽量保证这1万人与30万人特征差不多。比如可能这30万人中男女比例是1：1.2，那这1万人也按这个比例选择。等等。

当然，不管如何抽样，总会存在抽样误差。举个例子，这一次你用随机方法抽取了1万人，能够计算一个数值，比如糖尿病发病率。假设你重新抽取1万人，仍然用随机方法，那第二次抽取的1万人肯定跟第一次不一样（1万个随机数不可能完全一样），那么计算的糖尿病发病率肯定也不一样。如果你再抽取第3次、第4次、……，每一次抽取的1万人都不一样，每一次计算的发病率也都不一样。这种不一样就是抽样误差。如果每次抽样样本的发病率差别都很小，就表明抽取的样本较为稳定，代表性比较好，也就是抽样误差小。如果各次抽样样本的发病率差别很大，则表明抽取的样本不稳定，代表性较差，也就是抽样误差大。

如何估计抽样误差？我们已经说过，可以用多次抽样的结果之间的差别大小来估计抽样误差，但实际中我们不可能真的做这么多次的重复抽样，否则你的老板要疯掉了。医学统计学中，抽样误差一般用标准误来估计。标准误这一名词在很多统计方法中都会碰到，如t检验、线性回归、logistic回归等各种回归。如果标准误较小，说明抽样误差小，样本代表性较好，结果较为可靠。但如果标准误较大，说明抽样误差大，提示样本代表性不强，这种情况下一般需要加大样本量，否则结果不可靠。

这么多年来，这么多统计学家拼了命地研究新方法是为了干什么呢？就是为了减少那么一点点的抽样误差，让结果变得更可靠。所以我们说不同数据用不同的方法，条件不一样时用不一样的方法，是为了干什么呢？就是为了减少标准误，让结果更可靠。

最后一句话结尾：统计学起源于变异，发展于变异，结束于变异，整个统计学发展都是围绕变异。
