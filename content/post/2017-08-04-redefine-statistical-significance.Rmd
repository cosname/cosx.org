---
title: 72位著名统计学家呼吁提高统计显著性水平以提升科学研究的可重复性
author: 战立侃
date: '2017-08-07'
slug: redefine-statistical-significance
categories:
  - 统计推断
  - 统计软件
---

本文主要内容来自 Benjamin 等 72 位科学家将于近期 (2017) 发表在《自然人类行为》杂志上的文章。读者还可以参看 Chawla 于 8 月 3 日发表在 《自然》 杂志的相关评论。

# 1. 简单介绍

由于可重复性问题 (lack of reproducibility) 不高，基于统计显著性 (statistically significant) 结果而得出的新科学发现 的有效性正引起越来越多科学家的关注。导致某项研究可重复性差的原因有很多，如多重检验 (multiple testing)、p值操控 (p-hacking)、发表偏差 (publication bias)、以及统计效力过低 (underpowered) 等。导致实验可重复性不高的一项更直接的原因是：研究者用于支持新发现的**证据标准过低**。一项研究如果把统计显著性定义在 *p < 0.05* 的水平上，那么就算没有实验设计、实验程序和结果报告方面的问题，该研究也依然会产生非常高的**假阳性率** (hight rate of false positives)。

由此，科学家建议传统上把统计显著性水平定义在 *P < 0.05* 的相关学术领域，研究者应该把显著性水平提高到 *P < 0.005*。这一改变将显著提高这些领域中科学研究的可重复性水平。当然在旧标准下具有显著性但没有达到新显著性标准的结果，即显著性水平处于 *0.005 < P < 0.05* 的结果将被称作**倾向于显著** (sugestive)。

当然该建议并不涉及已经发表的研究，也不涉及已经采用更为严苛的显著性水平的科学研究领域，如基因组学 (genoics) 和高能物理研究 (high-energy physics) 等。

该建议将仅适用于涉及零假设检验的显著性检验中。当然，其他一些别的方法也可以提高研究的可重复性，如基于某些清晰界定的模型假设的贝叶斯因子或其他后验方法，都比 *P*-值优越。然而，改变 *P*-值的显著性水平最为直接，尤其是对于某些没有受过专业训练的人来说，而且也更容易获得大范围的认可。

# 2. 证据强度

在基于观测值 $x_{obs}$，对零假设 $H_0$ 和 备择假设 $H_1$ 的点假设检验中，*P*-值指的是在零假设正确的前提下，某个检验统计量 (test statistic) 与观测值 (observed value) 一样极端或者比观测值更极端的概率。如果 *P*-值位于提前设定的 I 类错误 (Type I) 的临界值 $\alpha=0.05$ 之下，那么零假设就被拒绝，我们就说结果在统计上显著 (statistically significant)。

从贝叶斯角度来看，假设检验更直接的证据来自于备择假设 $H_1$ 和零假设 $H_0$ 发生概率的比率 (Odds)。根据贝叶斯规则 (Bayes' Rule)，这个比率可以表示为：

$$
\frac{\text{Pr }(H_1|X_{obs})}{\text{Pr }(H_0|X_{obs})}=
\frac{\text{Pr }(X_{obs}|H_1)}{\text{Pr }(X_{obs}|H_0)}\times
\frac{\text{Pr }(H_1)}{\text{Pr }(|H_0)}=
BF \times (\text{prior odds}) 
$$

这个公式中，*BF* 是**贝叶斯因子** (Bayes factor) 的简称。贝叶斯因子是研究者可以从观测数据中计算出来的证据。按照 Kass 和 Raftery (1995) 的观点，贝叶斯因子的大小和证据强度 (strength of evidence) 存在以下关系：

|贝叶斯因子大小|否定零假设的证据强度|
|:---:|:---:|
|1-3.2|不值一提|
|3.2-10|显著的 (Substantial)|
|10-100|强 (Strong)|
|>100|确定的 (Decisive)|
|||

**先验概率** (prior odds) 需要通过研究者的前期假设、科学研究共识、或相同领域中相似研究问题的其他研究中获得。研究中多重检验、*P*-值操控、出版偏差等都会削弱前人研究中相关证据的可信性。例如，研究中改变假设检验涉及的整体的行为等都会降低该先验比率。目前为止，预测市场 (Prediction markets) 和可重复性研究领域的研究者都认为心理科学研究中，备择假设和零假设的先验比率仅为 *1:10* 左右。癌症临床应用 (cancer clinical trials) 研究领域的先验概率也为 *1:10* 左右。而在前临床的生物医学研究 (preclinical biomedical reaearch) 中，先验比率会更低。

*P*-值和贝叶斯因子之间并不存在一一对应的关系，因为贝叶斯因子受备择假设 $H_1$ 的影响。但在某些特定前提假设条件下，某些特定统计量的贝叶斯因子和 *P*-值之间是存在某些特定关系的。图 1a 和图 1b 描述了 *P*-值和贝叶斯因子之间的关系。在不损失结果一般性的前提下，我们把 *P*-值界定为从一个平均值为 0、标准差为 1 的正态分布的随机变量中，选取一个平均值为 $\mu$ 的独立同分布样本 (An independent and identically distributed sample) 的双尾检验的概率值。图中贝叶斯因子大小的计算方法可以有如下几种：

- **效力曲线** (Power) 表示在双尾检验条件下，I 类错误为 5%，统计效力为 75% 时计算出来的贝叶斯因子的大小。
- **似然值比率范围** (likelihood ratio bound)。 Berger 和 Sellke (1987) 认为，在假定备择假设正确的前提下，如果 $H_1$ 是以 $H_0$ 为中心呈对称分布的，那么贝叶斯因子大小的上限可以用下面公式计算 $BF = 1/(2\times \exp(\frac{1}{2}t^2))$，$t$ 指 I 类错误的大小。
- **均匀最大功效贝叶斯检验** (Uniformly Most Powerful Bayesian Test, UMPBT) 的计算方法来自 Johnson (2013)。该方法与 $\alpha = 0.005$ 的双尾检验类似，即备择假设处于 $\pm 2.81$ 时贝叶斯因子的大小。注意，当统计效力为 80% 时，效力曲线与该曲线几乎重合 (图1b)。
- **局部 $H_1$ 范围** (Local-$H_1$ Bound)。Sellke、Bayarri 和 Berger (2001) 认为当备择假设是一个以零假设为众数的单峰分布 (unimodal)，并满足某些限制条件时，贝叶斯因子的上限将不超过 $BF=1/(-\exp(1) \cdot p \ \cdot \ln(p))$，$p$ 即为 $p$-值的大小。

```{r echo = FALSE, eval = TRUE}
bff <- function(
type1 = 0.05, # alpha level is 0.05/2
type2 = 0.25, # beta is 0.25, so that power is 1-0.25 = 0.75
UMPTB = 0.005
){
p = 1 - c(9000 : 9990) / 10000
xbar = qnorm(p = 1 - p / 2, mean = 0, sd = 1)

## alternative based on 80% POWER IN 5% TEST
muPower = qnorm(p = 1 - type2, mean = 0, sd = 1) +
          qnorm(p = 1 - type1 / 2, mean = 0, sd = 1)  # mu of the alternative with the power of 75%
bfPow = 0.5 * (dnorm(x = xbar, mean =  muPower, sd = 1) +
               dnorm(x = xbar, mean = -muPower, sd = 1)) /
               dnorm(x = xbar, mean = 0, sd = 1)
muUMPBT = qnorm(p = 1 - UMPTB / 2, mean = 0, sd = 1)
bfUMPBT = 0.5 * (dnorm(x = xbar, mean =  muUMPBT, sd = 1) +
                 dnorm(x = xbar, mean = -muUMPBT, sd = 1)) /
                 dnorm(x = xbar, mean = 0, sd = 1)

## two-sided "LR" bound
bfLR = 0.5 / exp(- 0.5 * xbar ^ 2)
bfLocal = -1 / (exp(1) * p * log(p))  # Local bound; no need for two-sided adjustment
yy <- cbind(bfLR, bfLocal)

## Coordinates for dashed lines
data = data.frame(p, bfLocal, bfLR, bfPow, bfUMPBT)
U_005 = max(data[data$p == "0.005", -1])
L_005 = min(data[data$p == "0.005", -1])
U_05  = max(data[data$p == "0.05", -1])
L_05  = min(data[data$p == "0.05", -1])

# plot margins
# par(family = "Source Han Serif CN") # STKaiti                                     
par(mai = c(0.8, 0.8, 0.1, 0.6))
par(mgp = c(2, 1, 0))
matplot(p, yy, type = 'n', log = 'xy',
        xlab = expression(paste(italic(P) , "-value")),
        ylab = "Bayes Factor", 
        ylim = c(0.3, 100), bty = "n", xaxt = "n", yaxt = "n")
lines(p, bfPow, col = "red", lty = 1, lwd = 2)
lines(p, bfLR, col = "black", lty = 2, lwd = 2)
lines(p, bfUMPBT, col = "blue", lty = 3, lwd = 2)
lines(p, bfLocal, col = "#56B4E9", lty = 4, lwd = 2)
legend(x = 0.015, y = 100,
       legend = c(expression(paste("Power")), "Likelihood Ratio Bound", "UMPBT", expression(paste("Local-", italic(H)[1]," Bound"))),
       lty = 1:4, lwd = 2, col = c("red", "black", "blue", "#56B4E9"), cex = 0.8)
## customizing axes
# x axis
axis(side = 1,
  at = c(-2, 0.001, 0.0025, 0.005, 0.010, 0.025, 0.050, 0.100, 0.14),
  labels = c("", "0.0010", "0.0025", "0.0050", "0.0100", "0.0250", "0.0500", "0.1000", ""),
  lwd = 1, tck = -0.01, padj = -1.1, cex.axis = 0.8)

# y axis on the left - main
axis(side = 2,
     at = c(-0.2, 0.3, 0.5, 1, 2, 5, 10, 20, 50, 100),
     labels = c("", "0.3", "0.5", "1.0", "2.0", "5.0", "10.0", "20.0", "50.0", "100.0"),
     lwd = 1, las = 1, tck = -0.01, hadj = 0.6, cex.axis = 0.8)

#y axis on the left - secondary (red labels)
axis(side = 2, at = c(L_005, U_005),
     labels = c(formatC(L_005, digits = 2, format = "f"), formatC(U_005, digits = 2, format = "f")),
     lwd = 1, las = 1, tck = -0.01,
     hadj = 0.6, cex.axis = 0.6, col.axis = "red")

#y axis on the right - main
axis(side = 4, at = c(-0.2, 0.3, 0.5, 1, 2, 5, 10, 20, 50, 100),
     labels = c("","0.3","0.5","1.0","2.0","5.0","10.0","20.0","50.0","100.0"),
     lwd = 1, las= 1, tck = -0.01, hadj = 0.4, cex.axis = 0.8)

# y axis on the right - secondary (red labels)
axis(side = 4, at = c(L_05, U_05),
     labels = c(formatC(L_05, digits = 2, format = "f"), formatC(U_05, digits = 2, format = "f")),
     lwd = 1, las = 1, tck = -0.01, hadj = 0.4, cex.axis = 0.6, col.axis = "red")

### dashed lines
segments(x0 = 0.000011, y0 = U_005, x1 = 0.005, y1 = U_005, col = "gray40", lty = 2)
segments(x0 = 0.000011, y0 = L_005, x1 = 0.005, y1 = L_005, col = "gray40", lty = 2)
segments(x0 = 0.005, y0 = 0.00000001, x1 = 0.005, y1 = U_005, col = "gray40", lty = 2)
segments(x0 = 0.05, y0 = U_05, x1 = 0.14, y1 = U_05, col = "gray40", lty = 2)
segments(x0 = 0.05, y0 = L_05, x1 = 0.14, y1 = L_05, col = "gray40", lty = 2)
segments(x0 = 0.05, y0 = 0.00000001, x1 = 0.05, y1 = U_05, col = "gray40", lty = 2)
}
```

```{r label = `Figure_1_A`, echo = FALSE, eval = TRUE}
bff()
```

图1a. $P$-值和贝叶斯因子大小的关系

```{r label = "Figure_1_B", echo = FALSE, eval = TRUE}
bff(type2 = 0.2)
```

图1b. $P$-值和贝叶斯因子大小的关系。效力曲线是按统计效力为 80% 计算出来的。

根据图 1a-b 所示，显著性水平为 $P < 0.05$ 的双尾检验所对应的贝叶斯因子仅为 $2.5 - 3.4$ 之间。此时否定零假设的证据是非常弱的。如果我们把研究的先验概率设定为 $1:10$，此时备择假设发生的可能性仅为零假设发生可能性的 $\frac{1}{3} = 3.4 \times \frac{1}{10}$ ！

# 3. 新标准的好处？

显著性标准是人为设定，该设定需要在 I 类错误和 II 类错误之间的进行权衡。选择 $0.005$ 作为新标准至少有两个好处。首先，显著性水平为 $P = 0.005$ 的双尾检验所对应的贝叶斯因子大小约为 $14-26$ 之间，这说明证据强度是较强的。

其次，在多数研究领域，$P < 0.005$ 所导致的假阳性率 (false positive rate) 水平是合理和可接受的。假阳性指研究者得出了统计上显著，即得出了拒绝零假设的结论，但实际上零假设是正确的。如果用 $\phi$ 表示零假设正确的概率，$(1-\beta)$ 表示正确拒绝零假设的统计效力的大小，$\alpha$ 表示 I 类错误和显著性水平的大小，那么随着被检验整体的变大，假阳性率可以用如下公式表示：

$$
\text{false positive rate} \approx 
\frac
{\alpha\phi}
{\alpha\phi + (1-\beta)(1-\alpha)}
$$

上述公式显示假阳性率受先验概率($\frac{1-\phi}{\phi}$)、显著性水平、和统计效力的共同影响。如果把先验概率设定在 $1:40$、$1:10$、和 $1:5$ 三个水平，显著性水平设定为 $p < 0.05$ 或 $p < 0.005$，那么统计效力和假阳性率的关系可以用下图表示：

```{r label = "Figure_2", echo = FALSE, eval = TRUE}
#graph margins
pow1 = c(5 : 999) / 1000 # power range for 0.005 tests 
pow2 = c(50 : 999) / 1000 # power range for 0.05 tests 

pow   <- c("pow1", "pow2", "pow2", "pow1",  "pow2",  "pow1")
alpha <- c( 0.005,   0.05,   0.05,  0.005,    0.05,   0.005)
pi0   <- c(   5/6,    5/6,  10/11,  10/11,   40/41,   40/41)
lty   <- c(     1,      2,      2,      1,       2,       1)
col   <- c("blue", "blue",  "red",  "red", "green", "green")
df <- data.frame(pow, alpha, pi0, lty, col, stringsAsFactors=FALSE)

ddata <- function(
 pow = "pow1", 
 alpha = 0.005, 
 pi0 = 5/6, 
 id
){
 N = 10^6
 pow = eval(parse(text = pow))
 # yy = alpha * N * pi0 / (alpha * N * pi0 + pow[id] * (1 - pi0) * N)
 yy = alpha * pi0 /(alpha * pi0 + pow[id] * (1 - pi0))
 return(yy)
}

lline <- function(x
){
pow = df[x, 1]
alpha = df[x, 2]
pi0 = df[x, 3]
lty = df[x, 4]
col = df[x, 5]
xx = eval(parse(text = pow))
yy = ddata(pow = pow, alpha = alpha, pi0 = pi0)
lines(xx, yy, lty = lty, col = col, lwd = 2)
}

# png("Figure_2.png", width = 10, height = 8, units = "in", res = 600) # Print the plot 
#par(family = "Source Han Serif CN") # STKaiti                                     
par(mai = c(0.8, 0.8, 0.1, 0.1)) 
par(mgp = c(2, 1, 0))
plot(x = pow1, y = ddata(), type='n', ylim = c(0, 1), xlim = c(0, 1.5), 
     xlab = 'Power',
     ylab = 'False positive rate', 
     bty = "n", xaxt = "n", yaxt = "n") 
#grid lines
segments(x0 = -0.058, y0 = (0:5) * 0.2, x1 = 1, lty = 1, col = "gray92")
for (x in 1:6) lline(x)

#customizing axes 
aat <- c(-0.5, 0, 0.2, 0.4, 0.6, 0.8, 1.0)
llabels <- c("", "0.0", "0.2", "0.4", "0.6", "0.8", "1.0")
llegend <- c("Prior odds = 1:40", "Prior odds = 1:10", "Prior odds = 1:5") 
#llegend <- c("先验概率 = 1:40", "先验概率 = 1:10", "先验概率 = 1:5") 
axis(side = 2, at = aat, labels = llabels, 
  lwd = 1, las = 1, tck = -0.01, hadj = 0.4, cex.axis = .8)
axis(side = 1, at = aat, labels = llabels,
  lwd = 1, las = 1, tck = -0.01, padj = -1.1, cex.axis = .8)
legend(x = 1.05, y = 1, legend = llegend, 
  pch = c(15, 15, 15), col = c("green", "red", "blue"), cex = 1)
  
library(pBrackets)
odd_1_5_1  <- ddata(pow = "pow1", alpha = 0.005, pi0 = 5/6, id = 995)
odd_1_5_2  <- ddata(pow = "pow2", alpha = 0.05, pi0 = 5/6, id = 950)
odd_1_10_2 <- ddata(pow = "pow2", alpha = 0.05, pi0 = 10/11, id = 950)
odd_1_10_1 <- ddata(pow = "pow1", alpha = 0.005, pi0 = 10/11, id = 995)
odd_1_40_2 <- ddata(pow = "pow2", alpha = 0.05, pi0 = 40/41, id = 950)
odd_1_40_1 <- ddata(pow = "pow1", alpha = 0.005, pi0 = 40/41, id = 995)

t1label <- expression(paste(italic(P), " < 0.05 threshold"))
t2label <- expression(paste(italic(P), " < 0.005 threshold"))
text(1.11, (odd_1_5_2 + odd_1_40_2)/2, label = t1label, cex = 0.9,adj=0) 
text(1.11, (odd_1_5_1 + odd_1_40_1)/2, label = t2label, cex = 0.9,adj=0)
brackets(1.03, odd_1_40_1, 1.03, odd_1_5_1, h = NULL, ticks = 0.5, curvature = 0.7, type = 1, col = 1, lwd = 1, lty = 1, xpd = FALSE)
brackets(1.03, odd_1_40_2, 1.03, odd_1_5_2, h = NULL, ticks = 0.5, curvature = 0.7, type = 1, col = 1, lwd = 1, lty = 1, xpd = FALSE) 
#dev.off()
```

图 2 显示，低统计效力加上低的显著性水平 $\alpha=0.05$ 将产生高比率的假阳性率。例如，如果先验概率设定为 $1:10$，显著性水平设置为 $P<0.05$，那么无论统计效力处于什么水平，该分析的假阳性率将**不低于 33%**。统计效力在很多研究中实际上都比较低。而如果把显著性水平降为 *0.005*，则在绝大部分统计效力范围内，假阳性率可降到 *5%* 之下。

近期心理学和实验经济学领域中两个可重复性研究项目显示了提高显著性水平在增强研究的可重复性方面的重要作用。这两个项目分别分析了 96 项心理学研究和 16 项实验经济学研究，发现在 $p < 0.005$ 水平上显著的原初研究的重复率，比在 $0.005 < p < 0.05$ 水平上显著的原初研究的可重复率要高一倍：心理学研究可重复率分别为 50% 和 25%；实验经济学中这两个数字分别是 85%  和 44%。而在生物医学领域 96% 的研究采用的显著性水平均为 $P < 0.05$。而这些研究的重复率非常低，这也从侧面说明了提高显著性水平的作用。

# 4. 可能导致的批评

- 第一、提高显著性水平会提高 II 类错误，假阴性的比率 (false negative rate)。

没有达到新显著性标准水平的研究应该被视作**建议性的** (suggestive)。在有可能的情况下，这些结果将需要进一步的研究来进行确认。一项研究的结果不够肯定，而汇总和多项研究的结果却是可以非常确定的。另外需要注意的一点是，无法拒绝零假设  (fail to reject the null hypothesis) 并不意味着接受零假设。另外，如果研究者通过提高样本量的方式来让统计效力保持不变，那么提高显著性水平并不会导致假阴性率的提高。

对于大多数常见的统计分析而言，把显著性水平从 $\alpha=0.05$ 提高到 $\alpha=0.005$ 并且要保持 80% 的统计效力的话，样本量大约需要增加 70%。这就意味着目前实验设计和资金支持条件下，研究者能进行的研究数量将变少。但是，降低假阳性率的好处也是显而易见的：研究者将不需要投入大量资源去重复和验证前人发现的结果。

- 第二、该建议没有解决多重假设检验 (multiple testing)、p值操控(p-hacking)、发表偏差 (publication bias)、统计效力过低 (underpowered)、以及其他偏差如变量混淆、选择性报告、测量错误等所导致的问题。

提高显著性水平将是解决上述问题的补充而不是替代。提高研究可重复性的其他方法包括好的实验设计、预注册实验、ex ante power calculation 重复、清晰报告实验过程和实验分析方法等。

- 第三、显著性水平应该随着研究领域的不同而不同。

的确，一项研究显著性水平的选择应该受研究的先验概率、被检验假设的数量、实验设计、I 类和  II 类错误的后果、及其他因素的影响。
对于某些先验概率非常低 (远超出图 2 所表示的范围) 的探索性研究而言，研究者需要远比 0.005 更为严苛的显著性水平。 遗传学研究领域的科学家正是因为认识到了这一问题，才在十年前就把基因研究领域的显著性水平确定为 $5\times 10^{-8}$。高能物理研究领域的研究者也在很早前就确定了显著性水平的五个标准差原则 (5-sigma)，即显著性水平大约为 $P < 3\times 10^{-7}$。

本文的建议仅涉及图 2 可描述的相关研究领域，即先验概率处于$1/5 - 1/40$ 之间，传统上把显著性水平定义在 $P < 0.05$ 的研究领域。在这些领域中，研究者应该把显著性水平从两个标准差原则提高到三个标准差原则。

- 第四、提高显著性水平标准将影响对问题解决的真正方案的探索。而真正的解决方案将通过强调效应值大小、置信区间、把 P 值看成一个连续测量、和贝叶斯方法等，来逐步代替零假设的显著性检验。

大部分研究者都同意我们需要更合适的统计方法，但是对于什么是更好的替代品这个问题，研究者并没有达成一致。

# 5. 总结

对继续使用零假设的显著性检验的科学团体而言，把显著性水平的标准提高到 0.005的水平是非常容易操作的，而该改变将极大地提高科学研究的可重复性。

在此，研究者强调，这项提议是关于**证据强度的标准** (stabdard of evidence)，而不是关于政策制定和出版与否的标准。如果一项研究考察的是重要的科学问题，而且使用了严格的科学方法，那么无论结果是否达到了统计的显著性水平，这种研究都是重要的，都应该在顶级期刊上得到发表。这项提议不应该被用来作为拒绝研究结果发表的理由，尤其是当一项研究把显著性水平位于 $0.005 < P < 0.05$ 之间的结果正确地标记为了*建议性的*证据的时候。在提高统计显著性标准的同时，我们应该对高质量和高透明度的研究予以奖励，并把对研究者行为的影响降为最低。否则的话，显著性水平的提高将会影响到研究的质量和透明度。

# 6. 参考文献


1). Benjamin, D. J., et al.,. (2017). Redefine Statistical Significance. *Nature Human Behavior*. doi: http://osf.io/preprints/psyarxiv/mky9j

2). Berger, J. O., & Sellke, T. (1987). Testing a Point Null Hypothesis: The Irreconcilability of P Values and Evidence. Journal of the American Statistical Association, 82(397), 112-122. 

3). Chawla, D. S. (2017). P-value shake-up proposed. *Nature, 548*, 16-17. doi:10.1038/nature.2017.22375

4). Johnson, V. E. (2013). Revised standards for statistical evidence. *Proceedings of the National Academy of Sciences of the United States of America, 110*(48), 19313-19317. doi:10.1073/pnas.1313476110

5). Kass, R. E., & Raftery, A. E. (1995). Bayes Factors. *Journal of the American Statistical Association, 90*(430), 773-795. doi:10.1080/01621459.1995.10476572

6). Sellke, T., Bayarri, M. J., & Berger, J. O. (2001). Calibration of  p Values for Testing Precise Null Hypotheses. *The American Statistician, 55*(1), 62-71. doi:10.1198/000313001300339950
